\section{連結積とシャッフル積}\label{s1:連結積とシャッフル積} %{
	文字列の連結積とシャッフル積およびそれらの余積は互いに準同型と内積で
	結びついている。
	\begin{equation*}\begin{split} %{
		\Delta_*(w_1*w_2) &= (\Delta_*w_1) * (\Delta_*w_2) \\
		\Delta_\shuffle(w_1\shuffle w_2) 
			&= (\Delta_\shuffle w_1) \shuffle (\Delta_\shuffle w_2) \\
		w_1^t(w_2 * w_3) &= (\Delta_\shuffle w_1)^t(w_1\otimes w_2) \\
		w_1^t(w_2 \shuffle w_3) &= (\Delta_* w_1)^t(w_1\otimes w_2) \\
	\end{split}\end{equation*} %}
	連結余積とシャッフル余積は比較的簡単に計算できる。
	\begin{equation*}\begin{split} %{
		\Delta_*([a]*w) &= (1_W\otimes[a]+[a]\otimes1_W)*(\Delta_*w) \\
		\Delta_\shuffle[a_1a_2\cdots a_n] &= 1_W\otimes[a_1a_2\cdots a_n] \\
		&\; + [a_1]\otimes[a_2a_3\cdots a_n] \\
		&\; + [a_1a_2]\otimes[a_3a_4\cdots a_n] \\
		&\; + \cdots \\
		&\; + [a_1a_2\cdots a_n]\otimes1_W \\
	\end{split}\end{equation*} %}
	一方、シャッフル積の計算は難しいと思う。
	\begin{equation*}\begin{split} %{
		w_1\shuffle w_2 &= \sum_{w\in WA}w(\Delta_*w)^t(w_1\otimes w_2)
	\end{split}\end{equation*} %}
	漸化式の形に持ち込むと次のようになる。
	\begin{equation*}\begin{split} %{
		a\shuffle w &= \sum_{x\in WA}x(\Delta_*x)^t([a]\otimes w) \\
		&= \sum_{x\in WA}\jump{\nabla_{a}x=w}x \\
		\nabla_{a}[a_1a_2\cdots a_n]
		&= \jump{a=a_1}[a_2a_3\cdots a_n] \\
		&\;+ \jump{a=a_2}[a_1a_3\cdots a_n] \\
		&\;+ \cdots \\
		&\;+ \jump{a=a_n}[a_1a_2\cdots a_{n-1}] \\
	\end{split}\end{equation*} %}
	$\nabla_a$はライプニッツ則を満たすので微分であり、$a\shuffle w$は$a$に
	ついて$w$を積分したものになっている。
%s1:連結積とシャッフル積}

\section{二項分布とポアソン分布}\label{s1:二項分布とポアソン分布} %{
	二項分布で粒子数が大きくなるとポアソン分布で近似できることを導いておく。
	$N$個の粒子を２つの箱に分ける場合の粒子の分布確率を考える。
	粒子を確率$p$で一つ目の箱に入れ、確率$1-p$で二つ目の箱に入れるものとする。
	一つ目の箱に$r$個の粒子が入る確率$B(N,r,p)$は次のようになる。
	\begin{equation*}\begin{split} %{
		B(N,r,p) = \binom{N}{r}p^r(1-p)^{N-r}
	\end{split}\end{equation*} %}
	確率$B(N,r,p)$を
	\begin{itemize}\setlength{\itemsep}{-1mm} %{
		\item $N$が大きく、
		\item '平均'$\lambda=Np$が有限である
	\end{itemize} %}
	状況を考える。確率$B(N,r,p)$の対数をとると次のようになるが、
	\begin{equation*}\begin{split} %{
		\ln B(N,r,p) = \ln \binom{N}{r} + \ln p^r(1-p)^{N-r}
	\end{split}\end{equation*} %}
	一項目は次のようになり、
	\begin{equation*}\begin{split} %{
		\ln \binom{N}{r} &= - \ln r! + \ln \frac{N!}{(N-r)!} \\
		\ln \frac{N!}{(N-r)!} 
			&\overset{N\to\infty}{\simeq} N\ln N - N - (N-r)\ln (N-r) + (N-r) \\
			&= - N\ln (1-\frac{N}{r}) + r\ln (N-r) -r \\
			&\overset{N\to\infty}{\simeq} r\ln (N-r) \\
	\end{split}\end{equation*} %}
	二項目は次のようになる。
	\begin{equation*}\begin{split} %{
		\ln p^r(1-p)^{N-r} &= r\ln p + (N-r)\ln (1-p) \\
			&= r\ln\frac{p}{1-p} + N\ln (1-p) \\
			&= r\ln\frac{\lambda}{N-\lambda} + N\ln (1-\frac{\lambda}{N}) \\
			&\overset{N\to\infty}{\simeq}
				r\ln\frac{\lambda}{N-\lambda} - \lambda \\
	\end{split}\end{equation*} %}
	したがって、一項目と二項目をあわせて次のようになる。
	\begin{equation*}\begin{split} %{
		\ln B(N,r,p) 
			&\overset{N\to\infty}{\simeq}
				- \ln r! + r\ln (N-r) + r\ln\frac{\lambda}{N-\lambda} - \lambda \\
			&= -\ln r! + r\ln\lambda - \lambda + r\ln\frac{N-r}{N-\lambda} \\
	\end{split}\end{equation*} %}
	この式の四項目を落としたものがポアソン分布である。
%s1:二項分布とポアソン分布}

\section{Jeffreys事前分布}\label{s1:Jeffreys事前分布} %{
	$Y\in\mycal{Y}=\mybf{R}^n$を観測値、
	$\theta\in\Theta=\mybf{R}^k$を未知パラメータ、
	$p(Y|E,\theta)$を尤度とする。
	事後分布$p(E|Y)$
	\begin{equation*}\begin{split} %{
		p(E|Y)=\int_{\theta\in\Theta}d\theta p(Y|E,\theta)p(\theta|E)
	\end{split}\end{equation*} %}
	を求めたい時、事前分布$p(\theta|E)$をどのように定義すればよいだろうか？

	事前分布に対するなんらかの知見がある場合は問題ないが、まったく事前情報
	が無い場合はなんらかの分布を設定する必要がある。その一つの答えが
	Jeffreys事前分布である。
	Jeffreysの事前分布とは未知パラメータ$\Theta=\mybf{R}^k$の座標変換に
	対して事前分布の体積形式が不変になるように定義される。
	例えば$\theta=\theta(\eta)$という座標変換で次のようになる事前分布$P(-|E)$
	を定義する。
	\begin{equation*}\begin{split} %{
		d\theta P(\theta|E) = d\xi P(\eta|E)
	\end{split}\end{equation*} %}
	これはなんらか

	座標変換$\theta=\theta(\xi)$に対して次のようになるように事前分布を定義
	する。
	\begin{equation*}\begin{split} %{
		d\theta p(Y|E,\theta)p(\theta|E) = d\xi p(Y|E,\xi)p(\xi|E)
		%= d\xi (\det\partial_\xi\theta)^{\frac{1}{2}}p(Y|E,\xi)p(\xi|E)
	\end{split}\end{equation*} %}
	このような関数$p(Y|E,\theta),p(\xi|E)$は存在しないかあっても稀だろうが、
	尤度の極値近傍の線形変換に限定すれば成り立つようにすることはできる。
	尤度の対数をとって$p(Y|E,\theta)=\exp(-E_Y(\theta))$とすると、尤度の
	極値$\theta_*\in\Theta$は$\partial_\theta E_Y(\theta_*)=0$
	で与えられ、WKB近似は次のようになる。
	\begin{equation*}\begin{split} %{
		E_Y(\theta) &= E_Y(\theta_*) + \frac{1}{2}(\theta-\theta_*)^t
			\partial_\theta^2E_Y(\theta_*)(\theta-\theta_*)
			+ o(\zettai{\theta-\theta_*}^3) \\
		p(Y|E,\theta) &\simeq \exp\biggl(-E_Y(\theta_*)\biggr) 
			\exp\biggl(-\frac{1}{2}(\theta-\theta_*)^t
			\partial_\theta^2E_Y(\theta_*)(\theta-\theta_*)\biggr) \\
	\end{split}\end{equation*} %}
%s1:Jeffreys事前分布}

\section{最小二乗法再び}\label{s1:最小二乗法再び} %{
	$Y$を観測値、$X$を観測値$Y$を説明するモデル行列とする。
	\begin{equation*}\begin{split} %{
		P(X|Y) &\propto P(Y|X)P(X) \\
	\end{split}\end{equation*} %}
	モデルに未知係数$\xi$が含まれていた場合、確率$P(Y|X)$は次のようになる。
	\begin{equation*}\begin{split} %{
		P(Y|X) &\propto \sum_{\xi}P(Y|\xi,X)P(\xi|X) \\
	\end{split}\end{equation*} %}
	未知係数を$\beta\in\mybf{R}^{\dim(\beta)}$と$w\in\mybf{R}_+$として、
	確率密度を次のようにおく。
	\begin{equation*}\begin{split} %{
		p(Y|\beta,w,X) &= \biggl(\frac{w}{2\pi}\biggr)^{\frac{\dim(Y)}{2}}
			\exp\biggl(-\frac{w}{2}\zettai{Y-X\beta}^2\biggr) \\
		p(\beta|X)
			&= \biggl(\frac{m_\beta}{2\pi}\biggr)^{\frac{\dim(\beta)}{2}}
			\exp\biggl(-\frac{m_\beta}{2}\zettai{\beta}^2\biggr) \\
		p(w|X)
			&= \biggl(\frac{m_w}{2\pi}\biggr)^{\frac{1}{2}}
			w^{-\frac{1}{2}}\exp\biggl(-\frac{m_w}{2}w\biggr) \\
	\end{split}\end{equation*} %}
	$m_\beta$と$m_w$は最終的に$0$への極限をとる正の実数とする。
	すると観測値$Y$からモデル$X$が推定される確率は次のようになる。
	\begin{equation*}\begin{split} %{
		P(X|Y) \propto \int_{\beta\in\mybf{R}^{\dim(\beta)}}d\beta
			\int_{w\in\mybf{R}_+}dw p(Y|\beta,w,X)p(\beta|X)p(w|X)P(X)
	\end{split}\end{equation*} %}

%s1:最小二乗法再び}

\section{情報基準量}\label{s1:情報基準量} %{
	アルファベットの順序や歴史的な順序からは逆になるが、導出が簡単なBIC
	から述べることにする。

	\subsection{BIC}\label{s2:BIC} %{
		BICの導出はAICのそれと比べて単純である。
		BICでは、
		\begin{itemize}\setlength{\itemsep}{-1mm} %{
			\item 複数のモデルに対して、
			\item 同一の観測値からモデルが成り立つ確率を求め、
			\item その相対確率からモデルの適合具合を順序づける。
		\end{itemize} %}

		\begin{example}[対象となるモデルの集合]\label{eg:対象となるモデルの集合} %{
			次の$M_1$を観測値$Y$を線形モデルでフィッティングするモデル、
			$M_2$をシグモイドでフィッティングするモデルとする。
			\begin{equation*}\begin{split} %{
				M_1: Y = X\theta + \epsilon \\
				M_2: Y = \frac{1}{1 + e^{-X\theta}} \epsilon \\
			\end{split}\end{equation*} %}
			$M_1$と$M_2$の両方のフィッティングの結果を見比べたいときは
			対象となるモデルの集合を$\mycal{M}=\set{M_1,M_2}$とする。
		\end{example} %eg:対象となるモデルの集合}

		観測値を$n$次元ベクトルとし、観測値全体の集合を
		$\mycal{Y}\subseteq\mybf{R}^n$とする。
		対象となるモデルの集合を$\mycal{M}$とする。
		観測値$Y\in\mycal{Y}$からモデル$M\in\mycal{M}$が成り立つ確率を
		$P(M|Y)$とすると、ベイズの定理より、モデル$M$での$Y$の確率$P(Y|M)$と、
		モデルの事前確率$P(M)$の積で$P(M|Y)$を書くことができる。
		\begin{equation*}\begin{split} %{
			P(M|Y) \propto P(Y|M)P(M)
		\end{split}\end{equation*} %}
		$P(Y|M)$はモデルの定義より計算可能で、$P(M)$は経験によって決められるが
		未知であっても$M$が有限集合であれば等確率とすればよい。
		観測値$Y\in\mycal{Y}$からモデル$M$が選択される確率は次のようになる。
		\begin{equation*}\begin{split} %{
			P(M|Y) &= \frac{P(Y|M)P(M)}{Z_\mycal{M}} \\
			Z_{\mycal{M}} &= \sum_{m\in\mycal{M}}P(Y|M)P(M) \\
		\end{split}\end{equation*} %}

		\begin{note}[ベイズ分類]\label{note:ベイズ分類} %{
			ここで議論しているモデル選択は、文書の分類に用いられている
			単純ベイズ分類と本質的には同じである。
			モデル選択においてモデルをクラスと置き換えればベイズ分類となり、
			観測値の各成分が互いに独立であると仮定すると単純ベイズ分類となる。
		\end{note} %note:ベイズ分類}

		モデル$M$が持つフィッティング係数の集合を$\Theta_M$とする。

		\begin{example}[フィッティング係数の集合]\label{eg:フィッティング係数の集合} %{
			次の線形モデルの場合フィッティング係数$\theta$の集合は$\myop{R}^2$
			となり、モデル行列$X$はモデルの定数となる。
			\begin{equation*}\begin{split} %{
				\begin{pmatrix}
					Y_1 \\ Y_2 \\ Y_3
				\end{pmatrix} \sim \begin{pmatrix}
					X_{11} & X_{12} \\ X_{21} & X_{22} \\ X_{31} & X_{32}
				\end{pmatrix}\begin{pmatrix}
					\theta_1 \\ \theta_2
				\end{pmatrix}
			\end{split}\end{equation*} %}
		\end{example} %eg:フィッティング係数の集合}

		モデルのフィッティング係数を積分すると次のようになる。
		\begin{equation*}\begin{split} %{
			P(Y|M) \propto \sum_{\theta\in\Theta_M} P(Y|\theta,M)P(\theta|M)
		\end{split}\end{equation*} %}
		$\Theta_M$を実ベクトル空間だとしてWKB近似で積分を評価すると、
		例\ref{eg:線形モデルでの積分}の結果から次のようになる。
		\begin{equation*}\begin{split} %{
			\ln\biggl(\frac{P(M|Y)}{P(M)}\biggr)
			&\simeq \ln\bigl(P(Y|\theta_*,M)\bigr)
			- \frac{1}{2}\dim(\Theta_M)\ln\bigl(\dim(\mycal{Y})\bigr)
			+ \text{const.} \\
			\theta_* &= \myop{argmax}_{\theta\in\Theta_M}P(Y|\theta_*,M)
		\end{split}\end{equation*} %}
		右辺の定数項はモデル$M$に依存しない項である。
		この結果からBICが次のように定義される。
		
		\begin{definition}[BIC]\label{def:BIC} %{
			ベイズ情報基準$\myop{BIC}(M|Y)$は次のように定義される。
			\begin{equation*}\begin{split} %{
				\myop{BIC}(M|Y) &= 2\ln\bigl(P(Y|\theta_*,M)\bigr)
					- \dim(\Theta_M)\ln\bigl(\dim(\mycal{Y})\bigr) \\
				\theta_* &= \myop{argmax}_{\theta\in\Theta_M}P(Y|\theta_*,M)
			\end{split}\end{equation*} %}
		\end{definition} %def:BIC}

		\begin{example}[線形モデルでの積分]\label{eg:線形モデルでの積分} %{
			線形モデル$M:Y\sim X\theta$の場合、$P(Y|\theta,M)$は次のようになる。
			\begin{equation*}\begin{split} %{
				P(Y|\theta,M) = \exp\bigl(-\frac{1}{2}\zettai{Y-X\theta}^2\bigr)
			\end{split}\end{equation*} %}
			係数の事前確率$P(\theta|M)$を近似的に定数$(2\pi)^{-\frac{k}{2}}$
			としてしまうと、観測値と係数の次元を次のように定義して、
			\begin{equation*}\begin{split} %{
				n = \dim(\mycal{Y}),\quad k = \dim(\Theta_M)
			\end{split}\end{equation*} %}
			係数の積分は次のようになる。
			\begin{equation*}\begin{split} %{
				P(Y|M) &\propto (2\pi)^{-\frac{k}{2}}
					\int_{\theta\in\mybf{R}^k}d\theta P(Y|\theta,M) \\
				&= (2\pi)^{-\frac{k}{2}}\biggl(\frac{1}{2\pi}\biggr)^{\frac{n}{2}}
					\int_{\theta\in\mybf{R}^k}d\theta
					\exp\bigl(-\frac{1}{2}\zettai{Y-X\theta}^2\bigr) \\
				&= 
				\biggl(\frac{1}{2\pi}\biggr)^{\frac{n}{2}}
					\bigl(\myop{det}(X^tX)\bigr)^{-\frac{1}{2}}
					\exp\bigl(-\frac{1}{2}\zettai{Y-X\theta_*}^2\bigr) \\
				\theta_* &= (X^tX)^{-1}X^tY \\
			\end{split}\end{equation*} %}
			したがって、モデル$M$に依存しない因子を落とすと事後確率$P(M|Y)$は
			次のようになる。
			\begin{equation*}\begin{split} %{
				P(M|Y) \propto \bigl(\myop{det}(X^tX)\bigr)^{-\frac{1}{2}}
					\exp\bigl(-\frac{1}{2}\zettai{Y-X\theta_*}^2\bigr)P(M) \\
			\end{split}\end{equation*} %}
			ここで、因子
			\begin{equation*}\begin{split} %{
				\bigl(\myop{det}(X^tX)\bigr)^{-\frac{1}{2}}
			\end{split}\end{equation*} %}
			はモデル$M$に依存した定数なので、モデル間の比較をするためには
			残しておかなければならない。

			積分の変換係数$X^tX$を観測値の一成分あたりの量を$I_X=(X^tX)/n$
			とすると$\myop{det}(X^tX)=n^k\myop{det}(I_X)$となり、$I_X$を用いて
			次の式が得られる。
			\begin{equation*}\begin{split} %{
				\frac{P(M|Y)}{P(M)} \propto n^{-\frac{k}{2}}
					\bigl(\myop{det}(I_X)\bigr)^{-\frac{1}{2}}
					\exp\bigl(-\frac{1}{2}\zettai{Y-X\theta_*}^2\bigr) \\
			\end{split}\end{equation*} %}
			次元$k,n$に関係ない項を落とすとBICが導かれる。
			\begin{equation*}\begin{split} %{
				\ln\bigl(\frac{P(M|Y)}{P(M)}\bigr)
				&\simeq -\frac{1}{2}\zettai{Y-X\theta_*}^2 
				- \frac{k}{2}\ln(n)
				- \frac{1}{2}\ln\bigl(\myop{det}(I_X)\bigr)
				+ \text{const.} \\
				&\simeq -\frac{1}{2}\zettai{Y-X\theta_*}^2
				- \frac{1}{2}\dim(\Theta_M)\ln\bigl(\dim(\mycal{Y})\bigr)
				+ \text{const.} \\
				&\simeq \ln\bigl(P(Y|\theta_*,M)\bigr)
				- \frac{1}{2}\dim(\Theta_M)\ln\bigl(\dim(\mycal{Y})\bigr)
				+ \text{const.} \\
				\theta_* &= \myop{argmax}_{\theta\in\Theta_M}P(Y|\theta_*,M)
			\end{split}\end{equation*} %}
		\end{example} %eg:線形モデルでの積分}

		\begin{note}[フィッシャー情報行列]\label{note:フィッシャー情報行列} %{
			上記の例\ref{eg:線形モデルでの積分}の中で現れた量
			$I_X=(X^tX)/n$はフィッシャー情報行列と呼ばれるものである。
			尤度$P(Y|\theta)=P(Y|\theta,M)$を極値$\theta_*$の周りで展開すると
			次のようになり、$X^tX$が係数$\theta$の質量に対応することがわかる。
			\begin{equation*}\begin{split} %{
				\ln\bigl(P(Y|\theta)\bigr)
				&\propto -\frac{1}{2}\zettai{Y-X\theta_*}^2 
					+ \frac{1}{2}\zettai{X(\theta-\theta_*)}^2
			\end{split}\end{equation*} %}
			極値を与える係数$\theta_*$は$X^tX$が大きいと安定し$X^tX$が小さいと
			不安定になる。$X^tX$が大きい程極値$\theta_*$の値が正確になり、
			$X^tX$が小さい程極値$\theta_*$の値に遊びが大きくなると言ってもよいと
			思う。
		\end{note} %note:フィッシャー情報行列}
	%s2:BIC}
	\subsection{AIC}\label{s2:AIC} %{
		\begin{definition}[KL情報量]\label{def:KL情報量} %{
			$X$を集合、$P,Q$を$X$上の確率とする。
			次の量をKL情報量（Kullback-Leibler information/divergence）という。
			\begin{equation*}\begin{split} %{
				E_P[\ln(\frac{P}{Q})] 
				= \sum_{x\in X}P(x)\ln\bigl(\frac{P(x)}{Q(x)}\bigr)
			\end{split}\end{equation*} %}
		\end{definition} %def:KL情報量}

		KL情報量について次の基本的な命題が成り立つ。

		\begin{proposition}[KL情報量の基本的な性質]\label{prop:KL情報量の基本的な性質} %{
			$P,Q$を確率とする。KL情報量$E_P[\ln(\frac{P}{Q})]$は次の性質をもつ。
			\begin{enumerate}\setlength{\itemsep}{-1mm} %{
				\item $0 \le E_P[\ln(\frac{P}{Q})]$
				\item $0 = E_P[\ln(\frac{P}{Q})] \implies P=Q$
			\end{enumerate} %}
		\end{proposition} %prop:KL情報量の基本的な性質}
		\begin{proof} %{
			$X$を集合とし$P,Q$を$X$上の確率とする。
			\begin{enumerate}\setlength{\itemsep}{-1mm} %{
				\item 命題\ref{prop:KL情報量の基本的な性質-補題}を使って証明する。
				\begin{equation*}\begin{split} %{
					E_P[\ln(\frac{P}{Q})] &= \sum_{x\in X}P_x\ln(\frac{P_x}{Q_x})
					= - \sum_{x\in X}P_x\ln(\frac{Q_x}{P_x}) \\
					&\ge - \sum_{x\in X}P_x(\frac{Q_x}{P_x} - 1)
					= - \sum_{x\in X}(Q_x - P_x) = 0 \\
				\end{split}\end{equation*} %}
				\item 命題\ref{prop:KL情報量の基本的な性質-補題}から上記の証明で
				等号が成り立つのはすべての$x\in X$で$P_x=Q_x$が成り立つときのみ
				なことがわかる。
			\end{enumerate} %}
		\end{proof} %}
		\begin{proposition}[KL情報量の基本的な性質-補題]\label{prop:KL情報量の基本的な性質-補題} %{
			$p$を$0$以上の実数とする。このとき次の性質が成り立つ。
			\begin{enumerate}\setlength{\itemsep}{-1mm} %{
				\item $\ln(p) \le p-1$
				\item $\ln(p) = p-1 \implies p=1$
			\end{enumerate} %}
		\end{proposition} %prop:KL情報量の基本的な性質-補題}
		\begin{proof} %{
			$0\le p<1$の時、$\ln(p)<0$かつ$0<p-1$だから$\ln(p)<p-1$となる。
			$p=1$の時、$\ln(p)=0$かつ$p-1=0$だから$\ln(p)=p-1$となる。
			また、$y=(p-1)-\ln(p)$とすると$\partial_py=1-(1/p)$だから、
			$1<p$の時は$0<\partial_py$となり$(p-1)-\ln(p)$は$0$から増加していく。
			したがって、$1<p$の時も$\ln(p)<p-1$となる。
		\end{proof} %}
	%s2:AIC}

%s1:情報基準量}

\section{最小二乗法}\label{s1:最小二乗法} %{
	$Y\in\mybf{R}^n$を観測値、$X\in\mybf{R}^{n\times k}$をモデル行列、
	$\beta\in\mybf{R}^k$をフィッティング係数とする最小二乗法は
	残差$\epsilon=Y-X\beta$の二乗を最小にする係数$\beta$を求めることである。
	次の式を観測式という。
	\begin{equation*}\begin{split} %{
		Y = X\beta + \epsilon
	\end{split}\end{equation*} %}
	$\partial_\beta\zettai{\epsilon}^2=-2\epsilon^tX$だから、
	$\zettai{\epsilon}^2$の$\beta$に関する極小点$\beta_*$は$X^t\epsilon=0$
	によって定まる。$\beta_*$の満たすべき式は次のようになる。
	\begin{equation*}\begin{split} %{
		X^tX\beta_* = X^tY
	\end{split}\end{equation*} %}
	行列$X^tX$が逆を持てば$\beta_*=(X^tX)^{-1}X^tY$となる。

	観測値$Y$は母集団となるデータ$\mycal{Y}$からサンプルされたものだと考える
	と、$\mycal{Y}$での平均や分散などの統計量を考えることができる。
	$p$を$\mycal{Y}$の確率密度とし、平均を$E[\cdots]$、分散行列を$V[\cdots]$
	と書くことにする。
	\begin{equation*}\begin{split} %{
		E[f(Y)] &= \sum_{y\in\mycal{Y}}p(y)f(y) \\
		V[f(Y)] &= E\biggl[
			\bigl(f(Y)-E[f(Y)]\bigr)\bigl(f(Y)-E[f(Y)]\bigr)^t\biggr] \\
	\end{split}\end{equation*} %}
	$E[f(Y)]$や$V[f(Y)]$の記号$Y$は値を代入する変数ではなく統計操作を施した
	変数を明示するための記号である。

	一般に行列$A,B$の積$AB$が正方行列になれば$\myop{tr}(AB)=\myop{tr}(BA)$
	となる。成分で書けば$A_i^jB_j^i=B_i^jA_j^i$となることであるが、
	次の行列の例でみると
	\begin{equation*}\begin{split} %{
		A = \begin{pmatrix}
			A_{11} & A_{12} \\
			A_{21} & A_{22} \\
			A_{31} & A_{32} \\
		\end{pmatrix},\quad B = \begin{pmatrix}
			B_{11} & B_{12} & B_{13} \\
			B_{21} & B_{22} & B_{23} \\
		\end{pmatrix} \\
	\end{split}\end{equation*} %}
	次のようになっていることが確かめられる。
	\begin{equation*}\begin{array}{rcc} %{
		\myop{tr}(AB) &=& \myop{tr}\begin{pmatrix}
			A_{11}B_{11} + A_{12}B_{21} & * & * \\
			* & A_{21}B_{12} + A_{22}B_{22} & * \\
			* & * & A_{31}B_{13} + A_{32}B_{23} \\
		\end{pmatrix} \\
		& & || \\
		\myop{tr}(BA) &=& \myop{tr}\begin{pmatrix}
			B_{11}A_{11} + B_{12}A_{21} + B_{13}A_{31} & * \\
			* & B_{21}A_{12} + B_{22}A_{22} + B_{23}A_{32} \\
		\end{pmatrix} \\
	\end{array}\end{equation*} %}
	このことから分散行列のトレースをとればスカラー量の分散を得ることができる。
	\begin{equation*}\begin{split} %{
		\myop{tr}(V[Y])
		&= \myop{tr}\biggl(
			E\biggl[\bigl(Y-E[Y]\bigr)\bigl(Y-E[Y]\bigr)^t\biggr]\biggr) \\
		&= E\biggl[\myop{tr}\biggl(
			\bigl(Y-E[Y]\bigr)\bigl(Y-E[Y]\bigr)^t\biggr)\biggr] \\
		&= E\biggl[\myop{tr}\biggl(
			\bigl(Y-E[Y]\bigr)^t\bigl(Y-E[Y]\bigr)\biggr)\biggr] \\
		&= Y\text{の分散}
	\end{split}\end{equation*} %}

	係数$\beta_*$と残差$\epsilon_*=Y-X\beta_*$の母集団$\mycal{Y}$での平均は、
	$1_p$を$p\times p$単位行列とすると、次のようになる。
	\begin{equation*}\begin{split} %{
		E[\beta_*] &= (X^tX)^{-1}X^tE[Y] \\
		E[\epsilon_*] &= E[Y-X\beta_*] \\
			&= \bigl(1_n - X(X^tX)^{-1}X^t\bigr)E[Y] \\
			&\lcomment{$E[Y]=XE[\beta_*]$} \\
			&= \bigl(1_n - X(X^tX)^{-1}X^t\bigr)XE[\beta_*] \\
			&= 0
	\end{split}\end{equation*} %}
	分散行列は次のようになる。
	\begin{equation*}\begin{split} %{
		V[\beta_*] &= V[(X^tX)^{-1}X^tY] \\
			&= \bigl((X^tX)^{-1}X^t\bigr)V[Y]\bigl((X^tX)^{-1}X^t\bigr)^t \\
		V[\epsilon_*] &= V[Y-X\beta_*] \\
			&= V\bigl[\bigl(1_n - X(X^tX)^{-1}X^t\bigr)Y\bigr] \\
			&= \bigl(1_n - X(X^tX)^{-1}X^t\bigr)
				V[Y]\bigl(1_n - X(X^tX)^{-1}X^t\bigr)^t \\
	\end{split}\end{equation*} %}
	観測値の分散行列を非負の実数$\sigma_Y^2\in\mybf{R}$で次のように近似する。
	\begin{equation*}\begin{split} %{
		V[Y] \simeq \sigma_Y^21_n
	\end{split}\end{equation*} %}
	$\sigma_Y^2\in\mybf{R}$を$\mycal{Y}$の平均分散ということにする。
	すると、係数と残差の分散行列は次のように近似される。
	\begin{equation*}\begin{split} %{
		V[\beta_*] &\simeq \sigma_Y^2(X^tX)^{-1} \\
		V[\epsilon_*] &\simeq \sigma_Y^2\bigl(1_n - X(X^tX)^{-1}X^t\bigr) \\
	\end{split}\end{equation*} %}
	したがって、二乗残差の平均は次のように近似される。
	\begin{equation*}\begin{split} %{
		E[\epsilon_*^t\epsilon_*] &= \myop{tr}(V[\epsilon_*]) \\
		&\simeq \sigma_Y^2\myop{tr}\bigl(1_n - X(X^tX)^{-1}X^t\bigr) \\
		&\lcomment{}\dim(Y)=n,\;\dim(\beta)=k \\
		&= \sigma_Y^2\bigl(\dim(Y)-\dim(\beta)\bigr) \\
	\end{split}\end{equation*} %}
	さらに次の近似を使うと、
	\begin{equation*}\begin{split} %{
		E[\epsilon_*^t\epsilon_*] \simeq \epsilon_*^t\epsilon_*
	\end{split}\end{equation*} %}
	$\mycal{Y}$の平均分散$\sigma_\mycal{Y}^2$が観測値$Y$とモデル行列$X$で
	次のように近似されることになる。
	\begin{equation}\begin{split} %{
		\epsilon_*^t\epsilon_*
		&= \sigma_Y^2\bigl(\dim(Y)-\dim(\beta)\bigr) \\
	\end{split}\end{equation} %}
	この結果を使うと係数の分散行列は次のように近似される。
	\begin{equation}\label{eq:approx.beta.variance}\begin{split} %{
		V[\beta_*]
		&\simeq \frac{\epsilon_*^t\epsilon_*}{\dim(Y)-\dim(\beta)}
			(X^tX)^{-1}
	\end{split}\end{equation} %}

	最小二乗法は歴史も長く重々しい用語がいっぱい出てくる。
	それらの用語の意味を知らないとソフトウェアの説明や文献を読むときに
	困るのでそれらをまとめておく。
	\begin{itemize}\setlength{\itemsep}{-1mm} %{
		\item 変数$Y$を従属変数、目的変数、応答変数など、
		\item 変数$X$を独立変数、説明変数、回帰変数、入力変数、予測変数、
		デザイン行列、モデル行列など、
		\item 変数$\beta$を回帰係数、母数など、
		\item $\epsilon=Y-X\beta$を残差、誤差など、
	\end{itemize} %}
	と言う。

	\begin{todo}[結果の評価]\label{todo:結果の評価} %{
		次節\ref{s1:Rの最小二乗法をする関数}の最小二乗法を行うRの関数
		$\myop{lm}$の出力にあるように、
		最小二乗法によって係数$\beta$を求めるところまではわかりやすいが、
		その結果の評価がわかりにくい。
		Rの関数$\myop{lm}$の場合には、結果の評価はすべて分散によって
		行っている。観測値の標本分散や観測値の母集団について近似した分散
		などを用いて結果を評価している。
		これらの評価方法を幾何的に解釈できないものだろうか？
	\end{todo} %todo:結果の評価}
%s1:最小二乗法}

\section{Rの最小二乗法をする関数}\label{s1:Rの最小二乗法をする関数} %{
	Rの関数$\myop{lm}$は最小二乗法の解く関数である。
	例えば次のデータに対して
	\begin{cprog}
				 x=year-1999 Y=log(production)
		2000           1          12.93375
		2001           2          12.81754
		2002           3          12.70284
		2003           4          12.66118
		2004           5          12.61903
		2005           6          12.61753
		2006           7          12.57850
		2007           8          12.46975
		2008           9          12.39855
		2009          10          12.25514
	\end{cprog}
	関数$\myop{lm}$を適用すると次の結果を出力する。
	\begin{cprog}
		Call:
		lm(formula = Y ~ x)

		Residuals:
					Min        1Q    Median        3Q       Max 
		-0.065094 -0.033949  0.002665  0.038112  0.068172 

		Coefficients:
								 Estimate Std. Error t value Pr(>|t|)    
		(Intercept) 12.953890   0.033371  388.17  < 2e-16 ***
		x           -0.063365   0.005378  -11.78 2.47e-06 ***
		---
		Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 

		Residual standard error: 0.04885 on 8 degrees of freedom
		Multiple R-squared: 0.9455,     Adjusted R-squared: 0.9387 
		F-statistic: 138.8 on 1 and 8 DF,  p-value: 2.466e-06
	\end{cprog}
	変数を次のようにおいて$\myop{lm}$の出力を説明する。
	\begin{equation*}\begin{split} %{
		X = \begin{pmatrix}
			1 & 1 \\
			1 & 2 \\
			1 & 3 \\
			1 & 4 \\
			1 & 5 \\
			1 & 6 \\
			1 & 7 \\
			1 & 8 \\
			1 & 9 \\
			1 & 10 \\
		\end{pmatrix},\quad Y = \begin{pmatrix}
			414052 \\
			368626 \\
			328679 \\
			315267 \\
			302256 \\
			301804 \\
			290252 \\
			260341 \\
			242451 \\
			210059 \\
		\end{pmatrix},\quad \beta = \begin{pmatrix}
			\beta_1 \\
			\beta_2 \\
		\end{pmatrix}
	\end{split}\end{equation*} %}
	\begin{itemize}\setlength{\itemsep}{-1mm} %{
		\item Call:
		\begin{cprog}
			lm(formula = Y ~ x)
		\end{cprog}
		残差$\epsilon=Y-X\beta$の二乗和を最小にする係数$\beta\in\mybf{R}^2$を
		求めるということを示す。$\zettai{\epsilon^t\epsilon}$を最小にする
		$\beta$を$\beta_*$とする。
		\item Residuals:
		\begin{cprog}
						Min        1Q    Median        3Q       Max 
			-0.065094 -0.033949  0.002665  0.038112  0.068172
		\end{cprog}
		残差$\epsilon_*=Y-X\beta_*$の分布を示す。
		%
		\item Coefficients:
		\begin{cprog}
									 Estimate Std. Error t value Pr(>|t|)    
			(Intercept) 12.953890   0.033371  388.17  < 2e-16 ***
			x           -0.063365   0.005378  -11.78 2.47e-06 ***
		\end{cprog}
		Estimateは$\beta_*$を示し、Std. Errorは次の$\sigma_*$を示す。
		\begin{equation*}\begin{split} %{
			V[\beta_*]
			&= \frac{(\epsilon_*^t\epsilon_*)(X^tX)^{-1}}{\dim(Y)-\dim(\beta)} \\
			\sigma_* &= \bigl(\myop{diag}(V[\beta_*])\bigr)^{\frac{1}{2}} \\
		\end{split}\end{equation*} %}
		$V[\beta_*]$は近似した$\beta_*$の分散行列
		\eqref{eq:approx.beta.variance}であり、$\sigma_*$は$V[\beta_*]$
		の対角成分のルートをとったものである。
		t valueは$\beta_*/\sigma_{\beta_*}$を示し、$Pr(>|t|)$は次の積分の値
		を示している。
		\begin{equation*}\begin{split} %{
			\int_{\zettai{\beta_*}}^\infty dt \exp(-\frac{t^2}{2\sigma_*^2})
			= \int_{\zettai{\frac{\beta_*}{\sigma_*}}}^\infty
				dt \exp(-\frac{t^2}{2})
		\end{split}\end{equation*} %}
		大雑把には$1-Pr(>|t|)$は$\beta_*$が$0$でない確率を示す。
		一般にフィッティングするパラメータは少なければ少ない方がよい。
		したがって二乗残差に影響のないパラメータ、つまり$0$とおいても
		二乗残差に影響しないパラメータは省略したい。省略できるパラメータを
		示す目安として$Pr(>|t|)$を示している。$Pr(>|t|)$の値が大きいもの程
		省略してよい。
		\item 最後の部分
		\begin{cprog}
			Residual standard error: 0.04885 on 8 degrees of freedom
			Multiple R-squared: 0.9455,     Adjusted R-squared: 0.9387 
			F-statistic: 138.8 on 1 and 8 DF,  p-value: 2.466e-06
		\end{cprog}
		Residual standard errorは$\myop{tr}(V[\beta_*])$の値と、
		それは$(\epsilon_*^t\epsilon_*)(X^tX)^{-1}$を
		自由度$\dim(Y)-\dim(\beta)$で割ったものであることを示している。
		標本分散$V_Y[Y]$を次のようにおくと、
		\begin{equation*}\begin{split} %{
			E_Y[Y] = \frac{1}{n}\sum_{i=1}^{\dim(Y)}Y_i ,\quad
			V_Y[Y] = \sum_{i=1}^{\dim(Y)}(Y_i - E_Y[Y])^2
		\end{split}\end{equation*} %}

		Multiple R-squaredとAdjusted R-squaredはそれぞれ次の値を示す。
		\begin{equation*}\begin{split} %{
			\frac{\epsilon_*^t\epsilon_*}{V_Y[Y]},\quad
			\frac{(\epsilon_*^t\epsilon_*)\bigl(\myop{dim}(Y)-1\bigr)}
				{V_Y[Y]\bigl(\dim(Y)-\dim(\beta)\bigr)}
		\end{split}\end{equation*} %}
		Adjusted R-squaredのadjustedは
		$(\epsilon_*^t\epsilon_*)/\bigl(\dim(Y)-\dim(\beta)\bigr)$
		が$E[Y]=XE[\beta_*]$を使った$\mycal{Y}$の分散の推定で、
		$(\epsilon_*^t\epsilon_*)/\bigl(\myop{dim}(Y)-1\bigr)$
		が$Y$だけを使った$\mycal{Y}$の分散の推定であることを表している。

		F-statisticは次の値を示す。
		\begin{equation*}\begin{split} %{
			\frac{V_Y[X\beta_*]\bigl(\dim(Y)-\dim(\beta)\bigr)}
				{(\epsilon_*^t\epsilon_*)\bigl(\dim(\beta)-1\bigr)}
		\end{split}\end{equation*} %}
		ここで、$V_Y[X\beta_*]$は標本分散$V_Y[Y]$の$Y$を$X\beta_*$に置き換えた
		もので次のように定義される。
		\begin{equation*}\begin{split} %{
			V_Y[X\beta_*] = \sum_{i=1}^{\dim(Y)}\bigl((A\beta_*)_i - E_Y[Y]\bigr)^2
		\end{split}\end{equation*} %}
	\end{itemize} %}
%s1:Rの最小二乗法をする関数}

\section{シグモイド}\label{s1:シグモイド} %{
	\begin{definition}[シグモイド]\label{def:シグモイド} %{
		写像$f:\mybf{R}\to\mybf{R}$
		\begin{equation*}\begin{split} %{
			fx = \frac{1}{1+e^{-x}}
		\end{split}\end{equation*} %}
		をシグモイドという。
	\end{definition} %def:シグモイド}
	シグモイドを$fx$とすると、関数$fx-\frac{1}{2}$は原点$x=0$で反対称に
	なっている。
	\begin{equation*}\begin{split} %{
		f(-x) = 1-fx
	\end{split}\end{equation*} %}
	シグモイド$fx$の導関数は次のようになる。
	\begin{equation*}\begin{split} %{
		\frac{\partial(\ln f)}{\partial x} = 1 - f
		,\quad \frac{\partial^2(\ln f)}{\partial^2 x} 
			= -f\frac{\partial(\ln f)}{\partial x} \\
	\end{split}\end{equation*} %}
	シグモイド$fx$の振る舞いは次のようになる。
	\begin{equation*}\begin{matrix}
		x & -\infty & 0 & \infty \\
		f & 0 & \frac{1}{2} & 1 \\
		\ln f & -\infty & - \ln2 & 0 \\
		\partial_x \ln f & 1 & \frac{1}{2} & 0 \\
		\partial_x^2 \ln f & 0 & -\frac{1}{4} & 0 \\
	\end{matrix}\end{equation*} %}

	シグモイドは統計などに使われることが多いが、その際は、
	\begin{itemize}\setlength{\itemsep}{-1mm} %{
		\item 傾きを表す定数$k\in\mybf{R}$、
		\item 変曲点を表す定数$x_0\in\mybf{R}$、
		\item 最大値を表す定数$f_m\in\mybf{R}$、
	\end{itemize} %}
	を用いて、
	\begin{equation*}\begin{split} %{
		\frac{f_m}{1+e^{-k(x-x_0)}}
	\end{split}\end{equation*} %}
	という関数が用いられる。この関数はシグモイド$fx=\frac{1}{1+e^{-x}}$を
	変数変換$x\mapsto k(x-x_0)$、$f\mapsto \frac{f}{f_m}$したものである。

	与えられたデータ
	\begin{equation*}\begin{split} %{
		\begin{matrix}
		x_1 & x_2 & \cdots \\
		y_1 & y_2 & \cdots \\
		\end{matrix}
	\end{split}\end{equation*} %}
	をシグモイドで近似する手順を考える。シグモイド$f$を次のようにおき、
	\begin{equation*}\begin{split} %{
		f(k,x_0,f_0, f_1,x) &= f_0 + \frac{f_1}{1+e^{-k(x-x_0)}} \\
	\end{split}\end{equation*} %}
	与えられたデータに対して、定数$k,x_0,f_0,f_1$を決める。
	すべての定数をデータから計算で推定することは困難なので、
	\begin{itemize}\setlength{\itemsep}{-1mm} %{
		\item $f_0,f_1$をデータの最小最大値から、
		\item $x_0$をデータの微分$dy/dx$の最大値から
	\end{itemize} %}
	決めることする。すると、定数$k$は
	\begin{equation*}\begin{split} %{
		\widebar{y}=\frac{y-f_0}{f_1}
		,\quad \widebar{y}_x=\frac{\partial y}{\partial x}
	\end{split}\end{equation*} %}
	とおくと、
	\begin{equation*}\begin{split} %{
		k &= \frac{\widebar{y}_xx_0}{(\widebar{y}x_0)\bigl(1-(\widebar{y}x_0)\bigr)} \\
	\end{split}\end{equation*} %}
	によって決めることができる。
%s1:シグモイド}

\section{再販制度}\label{s1:再販制度} %{
	再販制度とは、製造業者が決定した小売価格を小売業者が変更できなくする
	法律である。日本では次の商品が再販制度の対象となっている。
	\begin{itemize}\setlength{\itemsep}{-1mm} %{
		\item 書籍
		\item 雑誌
		\item 新聞
		\item 音楽CD
		\item 音楽テープ
		\item 音楽レコード
	\end{itemize} %}
	音楽媒体が再販制度の対象になっている国は日本だけだそうだ。

	再販制度の必要性はいろいろ述べられているが、唯一納得のいく説明は、
	\begin{itemize}\setlength{\itemsep}{-1mm} %{
		\item 書籍の価格を全国均一にするため
	\end{itemize} %}
	というものである。 
	人口密度の高い値域では書籍一冊あたりの流通コストは下がるため、
	それが小売価格に反映された場合、都市部ほど情報収集や教材の購入が容易に
	なるという地域格差が生じてしまう。情報収集や教材の購入などは基本的な
	人権に近いものだと考えれば、そうしたものの地域格差を解消する手段として
	再販制度の導入は理解できる。
	
	\begin{todo}[地域格差の解消]\label{todo:地域格差の解消} %{
		流通コストの違いによって出版物の地域格差が生じるかどうかは微妙だろう。
		現在の日本において、一般の電化製品や工業製品の価格に、問題視するほどの
		地域格差が生じているとは考えにくい。
	\end{todo} %todo:地域格差の解消}

	再販制度を擁護する意見として次のようなものが見受けられる。
	\begin{itemize}\setlength{\itemsep}{-1mm} %{
		\item 商品の質の確保　\\
		製造業者により販売価格が決定されることにより、製造コストに見合った
		価格で販売することができる。
		\item 商品の多様性の確保　\\
		漫画に比べて学術書は少量生産になり、製造、流通のコストが高くなる。
		また、漫画の需要期間が短いのに対して、学術書は需要期間が長いために
		在庫管理のコストが高くなる。
	\end{itemize} %}
	これらの意見はこじつけに思われる。
	再販制度のもとでも、自由競争が行われていれば、
	\begin{itemize}\setlength{\itemsep}{-1mm} %{
		\item 製造業者間で価格競争が起きるし、
		\item 利益の出ない商品は販売されなくなる。
	\end{itemize} %}
	自動車の新車販売の市場では、実質的に製造業者が小売業者も兼ねている。
	こうした流通形態は法律の保護のもとに形成されたものではないだろう。

	地域格差の解消以外の理由では、再販制度の意義はカルテルの促進だと
	思われる。商品の価格決定に対して影響を与える人が多くなればなるほど
	カルテルは形成されにくくなると思われる。裏切り者が出れば、カルテルは
	崩壊するからである。カルテルを形成することで、製造業者の収益を確保し、
	結果的に、商品の質や多様性を確保することになるかもしれない。
	しかし、製造業者が価格を決定することが、直接、商品の質や多様性を
	確保することにはつながらない。
	
	カルテルを形成するためには、新規参入の製造業者を制限する必要がある。
	製造業者を小売業者に対して優位に立たたなければ、新規参入の製造業者
	を制限することができない。小売業者が自由に新規参入の製造業者の商品を
	販売できる状況を避ける必要がある。カルテルが小売業者を支配する方法は
	次のものが考えられる。
	\begin{itemize}\setlength{\itemsep}{-1mm} %{
		\item 製造業者が小売業者を兼ねる。\\
		自動車、鉄道、飛行機など製造そのものに大きな資本を必要とする工業製品
		はこのような形態をとっているものが多いように思われる。
		製造コストが流通コストを大きく上回る商品に見られる傾向かもしれない。
		\item 有力生産者を囲い込む。\\
		小説の場合は著者、音楽の場合は楽曲製作者、演奏者が
		\item 小売業者をヤク漬けにする。\\
		新規参入の製造業者の商品を販売した小売業者に対しては、カルテルからの
		商品をおろさないといった圧力をかける。この方法は、小売業者の商売が
		カルテルの商品へ強く依存していないと使えない。
	\end{itemize} %}

	製造業者が商品の小売価格を決定することと、製造業者と小売業者の間の商品の
	やり取りの方法は無関係と思うのが普通であろう。しかし、現状では両者は
	双子の兄弟のように組み合わせて議論される。通常、再販制度といった場合、
	\begin{itemize}\setlength{\itemsep}{-1mm} %{
		\item 製造業者が商品の小売価格を決定し、
		\item 小売業者は製造業者から商品を買い、ある一定期間内であれば、
		購入金額に近い額で製造業者に返品できる
	\end{itemize} %}
	制度のことを言うようである。ここでは、次のように法律が関与する事項と
	関与しない事項に言葉を分けて使う。
	\begin{itemize}\setlength{\itemsep}{-1mm} %{
		\item 再販制度とは製造業者が商品の小売価格を決定することで、
		\item 返品制度とは小売業者が製造業者が商品を返品する契約事項のこと。
	\end{itemize} %}

	レコード会社で起きていることについてのメモ。
	\begin{itemize}\setlength{\itemsep}{-1mm} %{
		\item メジャーとはカルテル以外の何者でもない。
		\item 小売店が消えていっている現状ではメジャーである意味が
		なくなってきている。
		\item 現在のメジャーが果たしている役割は、
		\begin{itemize}\setlength{\itemsep}{-1mm} %{
			\item マスメディアを使った販売促進、
			\item 商品売り出しのノウハウの提供、
		\end{itemize} %}
		といったものであろう。
	\end{itemize} %}

	タイアップとは、商品のテレビ広告に楽曲を使用してもらい、その代わりに
	楽曲の販売利益の一部を企業や広告代理店に譲ること。
	つまり、商品のテレビ広告に相乗りする枠を買い取ること。
	タイアップは、楽曲を多くの人に知らしめるというわかり易い役割以外に、
	小売業者の仕入れ量にも影響を与える。
%s1:再販制度}

\section{対称群の操作}\label{s1:対称群の操作} %{
	\begin{algorithm}
	\caption{置換から巡回置換を取り出す操作}
	\begin{cprog}
	doit: (out:OutputIterator[mutable]
		, perm:Array(Natural), value:Natural) -> Null {
		pre = {
			.for (i = 0; i .< perm.size; i += 1) {
				v = perm.get value;
				.assert (0 <= v).and(v < perm.size);
			}
			.for (i1 = 0; i1 .< perm.size; i1 += 1) {
				v1 = perm.get i1;
				.for (i2 = 0; i2 .< perm.size; i2 += 1) {
					v2 = perm.get i2;
					.assert (v1 .!= v2);
				}
			}
		}
		code = {
			out = out.push value;
			.while(v .!= value) {
				out = out.push v;
				v = perm.get v;
			}
		}
	}
	\end{cprog}
	\end{algorithm}
%s1:対称群の操作}

\section{群の表現}\label{s1:群の表現} %{
	表現について考える前に加群について成り立つことを列挙する。
	加群の係数を複素係数の群環とすると、群の表現を考えていることに
	なる。例えば、群$G$の複素ベクトル空間$V$への表現$\rho$を考える。
	$R\subseteq \myop{lin}(V,V)$を次のような元の集合とすると、
	\begin{equation*}\begin{split} %{
		\sum_{g\in G}r_g(\rho g)\quad\text{where }r_g\in \mybf{C}
		\quad\text{for all }g\in G
	\end{split}\end{equation*} %}
	$R$は複素係数の代数となり、$V$を左$R$加群とみなすことができる。

	以下では$R$を環とする。

	加群とその間の線形写像についての定義と命題を列挙する。

	\begin{definition}[部分加群]\label{def:部分加群} %{
		$V$を左$R$加群とする。$V$の部分集合$W\subseteq V$が次の性質を
		満たすとき、$W$を$V$の部分$R$加群という。
		\begin{equation*}\begin{split} %{
			v_1+v_2\in W \quad\text{for all }v_1,v_2\in W \\
			rv\in W \quad\text{for all }r\in R,\;v\in W \\
		\end{split}\end{equation*} %}
	\end{definition} %def:部分加群}

	\begin{definition}[線形写像]\label{def:線形写像} %{
		$V,W$を左$R$加群とする。次の性質を満たす写像$f:V\to W$を$R$線形写像
		という。
		\begin{itemize}\setlength{\itemsep}{-1mm} %{
			\item $f(v_1+v_2)=(fv_1)+(fv_2)\quad\text{for all }v_1,v_2\in V$
			\item $f(rv)=r(fv)\quad\text{for all }v\in V,\;r\in R$
		\end{itemize} %}
	\end{definition} %def:線形写像}

	\begin{definition}[線形写像全体]\label{def:線形写像全体} %{
		$V,W$を左$R$加群とする。
		$V$から$W$への$R$線形写像全体を$\myop{lin}_R(V,W)$と書く。
		特に、$R$が複素数の時は$\myop{lin}(V,W)=\myop{lin}_{\mybf{C}}(V,W)$
		と省略して書く。
	\end{definition} %def:線形写像全体}

	$V,W$を左$R$加群とする。$\myop{lin}_R(V,W)$に加法を次のように定義し、
	\begin{equation}\label{eq:線形写像の加法}\begin{split} %{
		(f_1+f_2)v = (f_1v)+(f_2v)
		\quad\text{for all }f_1,f_2\in \myop{lin}_R(V,W),\;v\in V
	\end{split}\end{equation} %}
	$R$とのスカラー積を次のように定義する。
	\begin{equation}\label{eq:線形写像のスカラー積}\begin{split} %{
		(rf)v = r(fv)
		\quad\text{for all }r\in R,\;f\in \myop{lin}_R(V,W),\;v\in V
	\end{split}\end{equation} %}
	これらの加法とスカラー積によって$\myop{lin}_R(V,W)$は左$R$加群となる。
	$\myop{lin}_R(V,W)$の定義より、
	\begin{equation*}\begin{split} %{
		(rf)v = rfv = frv
		\quad\text{for all }r\in R,\;f\in \myop{lin}_R(V,W),\;v\in V
	\end{split}\end{equation*} %}
	となることに注意する。

	$S$を$R$の部分環$S\subseteq R$とすると、$V,W$は左$R$加群であると同時に
	左$S$加群にもなり、$\myop{lin}_S(V,W)$が定義できる。
	$\myop{lin}_R(V,W)$に加法を次のように定義し、
	\begin{equation}\label{eq:線形写像の加法}\begin{split} %{
		(f_1+f_2)v = (f_1v)+(f_2v)
		\quad\text{for all }f_1,f_2\in \myop{lin}_S(V,W),\;v\in V
	\end{split}\end{equation} %}
	$R$とのスカラー積を次のように定義する。
	\begin{equation}\label{eq:線形写像のスカラー積}\begin{split} %{
		(rf)v = rfr^{-1}v
		\quad\text{for all }r\in R,\;f\in \myop{lin}_S(V,W),\;v\in V
	\end{split}\end{equation} %}
	
	$\myop{lin}_S(V,W)$の
	$R$とのスカラー積\eqref{eq:線形写像のスカラー積}と同様に、
	\begin{equation*}\begin{split} %{
		(rf)v = r(fv)
		\quad\text{for all }r\in R,\;f\in \myop{lin}_S(V,W),\;v\in V
	\end{split}\end{equation*} %}
	と定義すると、$\myop{lin}_R(V,W)$は$\myop{lin}_S(V,W)$の部分加群となる。
	\begin{equation*}\begin{matrix} %{
		S &\subseteq& R \\
		\myop{lin}_S(V,W) &\supseteq& \myop{lin}_R(V,W) \\
	\end{matrix}\end{equation*} %}

	Schurの補題を証明しておく。
	Schurの補題は加群の言葉だけで書くことができる。

	\begin{proposition}[線形写像の核と像]\label{prop:線形写像の核と像} %{
		$V,W$を左$R$加群とする。任意の$R$線形写像$f:V\to W$に対して
		$\myop{ker}f$は$V$の部分$R$加群となり、
		$\myop{im}f$は$W$の部分$R$加群となる。
	\end{proposition} %prop:線形写像の核と像}
	\begin{proof} %{
		$f\in \myop{lin}_R(V,W)$に対して次のことが成り立つ。
		\begin{itemize}\setlength{\itemsep}{-1mm} %{
			\item 任意の$v_1,v_2\in V$に対して、$fv_1=0$かつ$fv_2=0$ならば、
			$f(v_1+v_2)=0$となる。
			\item 任意の$v\in V$と$r\in R$に対して、$fv=0$ならば、
			$f(rv)=r(fv)=0$となる。
		\end{itemize} %}
		したがって、$\myop{ker}f$は$V$の部分$R$加群となる。
		また、
		\begin{itemize}\setlength{\itemsep}{-1mm} %{
			\item 任意の$v_1,v_2\in V$に対して、$(fv_1)+(fv_2)=f(v_1+v_2)$
			となる。
			\item 任意の$v\in V$と$r\in R$に対して、$r(fv)=f(rv)$となる。
		\end{itemize} %}
		したがって、$\myop{im}f$は$W$の部分$R$加群となる。
	\end{proof} %}

	\begin{definition}[単純加群]\label{def:単純加群} %{
		$V$を左$R$加群とする。$V$が$\set{0}$または$V$以外に部分加群
		を持たないとき、$V$を単純左$R$加群という。
	\end{definition} %def:単純加群}

	\begin{proposition}[Schurの補題]\label{prop:Schurの補題} %{
		$V,W$を空でない単純左$R$加群とする。$V$から$W$への$R$線形写像は、
		可逆または$0$への定数写像に限られる。
	\end{proposition} %prop:Schurの補題}
	\begin{proof} %{
		任意の$f\in \myop{lin}_R(V,W)$に対して、
		命題\ref{prop:線形写像の核と像}により、$\myop{ker}f$は$V$の
		$R$部分加群となる。したがって、$V$が単純左$R$加群という命題の仮定より、
		$\myop{ker}f$は$\set{0}$または$V$自身でなくてはならない。
		$\myop{ker}f=V$の場合は、$f$が$0$への定数写像になる。
		$\myop{ker}f=\set{0}$の場合は、
		\begin{equation*}\begin{split} %{
			fv_1=fv_2\implies f(v_1-v_2)=0\implies v_1-v_2\in\myop{ker}f
			\implies v_1=v_2 \\
			\quad\text{for all }v_1,v_2\in V
		\end{split}\end{equation*} %}
		より、$f$は$1:1$になる。また、命題\ref{prop:線形写像の核と像}により、
		$fV$は$W$の部分$R$加群となる。したがって、
		$W$が単純左$R$加群という命題の仮定より、$fV$は$\set{0}$
		または$W$自身でなくてはならない。$f$が$1:1$より、
		$fV=\set{0}$となるのは$V=\set{0}$の場合のみである。この場合は、
		$V$が空でないという命題の仮定に反する。
		$V\neq\set{0}$の場合、$fV=W$となり、$f$が$\myop{onto}$となる
		ことがわかる。
	\end{proof} %}

	ここから、表現特有の事柄について述べる。

	\begin{definition}[双対空間]\label{def:双対空間} %{
		$V$を$R$モジュール、$V$から複素数$\mybf{C}$への
		$\mybf{C}$線形写像全体を$V^\dag=\myop{lin}(V,\mybf{C})$とする。
		$V^\dag$を$V$の$\mybf{C}$双対空間という。
	\end{definition} %def:双対空間}

	\begin{definition}[双対表現]\label{def:双対表現} %{
		$V$を$R$モジュール、$V^\dag$を$V$の$\mybf{C}$双対空間とする。
		$G$をモノイド、$\rho$を$G$の$V$への表現とする。
		写像$\rho^\dag:G\to \myop{lin}(V^\dag,V^\dag)$を次の式が成り立つように
		定義する。
		\begin{equation*}\begin{split} %{
			\bigl((\rho^\dag g)v^\dag\bigr)(\rho g)w = v^\dag w
			\quad\text{for all }v^\dag \in V^\dag,\;w\in V,\; g\in G
		\end{split}\end{equation*} %}
		写像$\rho^\dag$を$\rho$の双対表現という。
	\end{definition} %def:双対表現}

	写像$\myhere^\dag:\myop{lin}(V^\dag,V^\dag)\to \myop{lin}(V,V)$
	を次のように定義すると、
	\begin{equation*}\begin{split} %{
		(fv^\dag)w = f^\dag w
		\quad\text{for all }v^\dag \in V^\dag,\;w\in V,\; f\in \myop{lin}(V^\dag,V^\dag)
	\end{split}\end{equation*} %}
	双対表現は次のようになる。
	\begin{equation*}\begin{split} %{
		v^\dag w = \bigl((\rho^\dag g)v^\dag\bigr)(\rho g)w
		= v^\dag(\rho^\dag g)^\dag(\rho g)w \\
		\quad\text{for all }v^\dag \in V^\dag,\;w\in V,\; g\in G
	\end{split}\end{equation*} %}
	したがって、$G$が群であれば、次の式が成り立つ。
	\begin{equation*}\begin{split} %{
		(\rho^\dag g)^\dag = \rho g^{-1}
		\quad\text{for all }g\in G
	\end{split}\end{equation*} %}
	また、$V$が$d$次元複素ベクトル空間$V=\mybf{C}^d$で、その双対空間が
	複素共役転置で与えられた場合、写像$\myhere^\dag$は冪等
	$(\myhere^\dag)^\dag=\myid$になり、
	\begin{equation*}\begin{split} %{
		\rho^\dag g = (\rho g^{-1})^\dag
		\quad\text{for all }g\in G
	\end{split}\end{equation*} %}
	となる。したがって、$\rho$がユニタリー表現の場合、
	\begin{equation*}\begin{split} %{
		\rho^\dag g = (\rho g^{-1})^\dag = \rho g
		\quad\text{for all }g\in G
	\end{split}\end{equation*} %}
	となる。
%s1:群の表現}

\section{合成列}\label{s1:合成列} %{
	$G=(G,m,1_G)$を群、$H_0,H_1,\dots,H_n$を、各$k=0,1,\dots,n-1$に対して
	$H_k$は$H_{k+1}$でない$H_{k+1}$の極大正規部分群とする。
	次のような極大正規部分群の系列である。
	\begin{equation*}\begin{split} %{
		\mybf{1}= H_0\subset H_1\subset \cdots\subset H_n=G
	\end{split}\end{equation*} %}
	$\mybf{1}=H_0\subset H_1\subset\cdots\subset H_n=G$を$G$の合成列といい、
	\begin{itemize}\setlength{\itemsep}{-1mm} %{
		\item $n$を合成の長さといい、
		\item 各$k=0,1,\dots,n-1$に対して$H_{k+1}/H_k$を合成因子という。
	\end{itemize} %}

	\begin{proposition}[Jordan-Holderの定理]\label{prop:Jordan-Holderの定理} %{
		群の任意の合成列の長さはすべて等しい。また、$G$を群とし、
		\begin{itemize}\setlength{\itemsep}{-1mm} %{
			\item $\mybf{1}=H_0\subset H_1\subset\cdots H_m=G$を$G$の合成列、
			$\widebar{H}_1=H_1/H_0,\widebar{H}_2=H_2/H_1,\cdots,
			\widebar{H}_m=H_m/H_{m-1}$をその合成因子、
			\item $\mybf{1}=I_0\subset I_1\subset\cdots I_m=G$を$G$の合成列、
			$\widebar{I}_1=I_1/I_0,\widebar{I}_2=I_2/I_1,\cdots,
			\widebar{I}_m=I_m/I_{m-1}$をその合成因子
		\end{itemize} %}
		とすると、ある$m$次の置換$\sigma$があって、各$k=1,2,\dots,m$に対して
		次の群同型が成り立つ。
		\begin{equation*}\begin{split} %{
			\widebar{H}_k \simeq \widebar{I}_{\sigma k}
			\quad\text{for all }k=1,2,\dots,m
		\end{split}\end{equation*} %}
	\end{proposition} %prop:Jordan-Holderの定理}
%s1:合成列}

\section{トークン分解}\label{s1:トークン分解} %{
	文字集合を$A$として次の文法を考える。
	\begin{equation}\label{eq:トークン分解その一}\begin{split} %{
		x_0 = x_1x_2 + x_3,\quad x_1 = a,\quad  x_2 = b,\quad  x_3 = ac \\ 
		a,b,c\in A,\:x_0,x_1,x_2,x_3\in \text{undeterminant}
	\end{split}\end{equation} %}
	この文法の状態遷移図を次のように表す。
	\begin{equation*}\xymatrix{
		& 1_W\otimes x_0 \ar[dl]_{a} \ar[dr]^{a} \\
		x_1\otimes x_2 \ar[d]^{b} & & a\otimes c \ar[d]^{c} \\
		x_1x_2\otimes 1_W  & &  x_3\otimes 1_W
	}\end{equation*}
	頂点を表すテンソル積の第一成分が確定したトークン分解を与え、
	第二成分がこれから起こり得るトークン分解を与える。
	文字列が与えられた文法として受理できるかどうかの判定だけなら、
	テンソル積の第二成分だけ追っていけばよいが、どのパターンとして受理された
	かを示すためには第一成分も追う必要がある。

	このことを文字列から文字列への写像として定式化してみる。
	$A=\set{a,b,c,\dots}$、$X=\set{x_0,x_1,x_2,x_3,\dots}$として、
	文法\eqref{eq:トークン分解その一}を$\myop{lin}(RWA,RWX)$の一点と解釈する。
	$\myop{lin}(RWA,RWX)$の元を、
	\begin{equation*}\begin{split} %{
		w_Xw_A^\dag,\;w_X\in WX,\;w_A\in WA
	\end{split}\end{equation*} %}
	という単項の線形和で書く。文法\eqref{eq:トークン分解その一}の場合は、
	$[x_1x_2][ab]^\dag+[x_3][ac]^\dag$という$\myop{lin}(RWA,RWX)$の元を
	指定したことになる。$\myop{lin}(RWA,RWX)$に積$m_*$を次のように定義する。
	\begin{equation*}\begin{split} %{
		(u_1w_1^\dag)*(u_2w_2^\dag) = (u_1*u_2)(w_1*w_2)^\dag
		\quad\text{for all }u_1,u_2\in WX,\;w_1,w_2\in WA
	\end{split}\end{equation*} %}
	すると、$\set{[x]\otimes1_W^\dag}_{x\in X}\simeq X$と
	$\set{1_W\otimes[a]^\dag}_{a\in A}\simeq A$が$\myop{lin}(RWA,RWX)$の
	生成系となる。$\myop{lin}(RWA,RWX)$を領域分割
	（節\ref{s1:領域分割のパターン}）することを考える。
	次の図を可換にする余積$\Delta$が求まれば、与えられた$\myop{lin}(RWA,RWX)$
	の元から状態遷移図を作成することができる。
	\begin{equation*}\xymatrix{
		RWA\otimes RWA \ar[r]^{m_*} \ar@{.>}[dr]_{\Delta\phi} 
		& RWA \ar[d]^{\phi} \\
		& RWX \\
	}\end{equation*}
	余積$\Delta$は次のようになる。
	\begin{equation*}\begin{split} %{
		\Delta w_Xw_A^\dag = w_X(\Delta_*w_A)^\dag
		\quad\text{for all }w_X\in WX,\;w_A\in WA
	\end{split}\end{equation*} %}
	$\Delta$を用いて$RWA$の$\myop{lin}(RWA,RWX)$への作用を
	次のように定義できる。
	\begin{equation*}\begin{split} %{
		(w_1\phi)w_2 = (\Delta\phi)(w_1\otimes w_2)
		\quad\text{for all }w_1,w_2\in WA,\;\phi\in \myop{lin}(RWA,RWX)
	\end{split}\end{equation*} %}
	この作用を用いると、文法\eqref{eq:トークン分解その一}は次のような
	状態遷移図として書くことができる。
	\begin{equation*}\xymatrix{
		& [x_1x_2][ab]^\dag+[x_3][ac]^\dag \ar[d]_{a} \\
		& [x_1x_2][b]^\dag+[x_3][c]^\dag \ar[dl]_{b} \ar[dr]^{c} \\
		[x_1x_2]1_W^\dag & & [x_3]1_W^\dag
	}\end{equation*}
	このように、余積$\Delta$によってどのパターンとして受理されたかまでを
	示す状態遷移図を書くことができる。
	しかし、余積$\Delta$による状態遷移図だけではトークン分解まではできない。
	入力ストリームから文字を一文字づつ読みながらトークン分解していく
	手続きを記述する方法を考える必要がある。

	仮想的な文字を導入してトークン分解を表す。
	文法\eqref{eq:トークン分解その一}の場合、次の文字を新規に追加する。
	\begin{equation*}\begin{split} %{
		X &= \set{x_1,x_2,x_3} \\
		\ket{X} &= \set{\ket{x_1},\ket{x_2},\ket{x_3}} \\
		\bra{X} &= \set{\bra{x_1},\bra{x_2},\bra{x_3}} \\
	\end{split}\end{equation*} %}
	$\ket{X}$と$\bra{X}$に次の代数関係を設定する。
	\begin{equation*}\begin{split} %{
		\bra{x}\ket{y} &= \jump{x=y}\braket{x|x} \\
		\bra{x}a_1a_2\cdots a_m\ket{y} 
		&= \jump{x=y}\bra{x}a_1a_2\cdots a_m\ket{x} \\
		& \quad\text{for all }x,y\in X,\;a_1a_2\cdots a_m\in A \\
	\end{split}\end{equation*} %}
	そして、文法\eqref{eq:トークン分解その一}を次のように書き直す。
	\begin{equation}\label{eq:トークン分解その二}\begin{split} %{
		x_0 &= \bra{x_1}a\ket{x_1}\bra{x_2}b\ket{x_2} + \bra{x_3}ac\ket{x_3} \\
		&= \biggl(\bra{x_1}+\bra{x_3}\biggr)a
		\biggl(\ket{x_1}\bra{x_2}b\ket{x_2}+c\ket{x_3}\biggr) \\
	\end{split}\end{equation} %}
	すると、状態遷移は次のように書き表される。
	\begin{equation*}\xymatrix{
		& 1_W\otimes x_0 \ar[d]^{(\bra{x_1}+\bra{x_3})a} \\
		& y_1\otimes z_1
		\ar[dl]_{\ket{x_1}\bra{x_2}b} \ar[dr]^{c} \\
		y_2\otimes z_2 \ar[d]_{\ket{x_2}}
		& & y_3\otimes z_3 \ar[d]^{\ket{x_3}} \\
		\bra{x_1}a\ket{x_1}\bra{x_2}b\ket{x_2}\otimes 1_W
		& & \bra{x_3}ac\ket{x_3}\otimes 1_W \\
	}\end{equation*}
%s1:トークン分解}

\section{文脈自由と木構造}\label{s1:文脈自由と木構造} %{
	次の文脈自由の文法
	\begin{equation*}\begin{split} %{
		x &= a + b_1xc_1, \quad a,b_1,c_1\in A, \;x\in\text{変数}
	\end{split}\end{equation*} %}
	は線形写像$\phi_1:RWA\to RWA$
	\begin{equation*}\begin{split} %{
		\phi_1 f = b_1fc_1 \quad\text{for all }f\in RWA
	\end{split}\end{equation*} %}
	を用いて、$(\exp \phi_1)a$によって列挙される。
	次の文脈自由の文法
	\begin{equation*}\begin{split} %{
		x &= a + b_1xc_1 + b_2xc_2xd_2, 
		\quad a,b_1,c_1,d_2\in A, \;x\in\text{変数}
	\end{split}\end{equation*} %}
	は\underbar{非}線形写像$\phi_2:RWA\to RWA$
	\begin{equation*}\begin{split} %{
		\phi_2 f = b_2fc_2fd_2 \quad\text{for all }f\in RWA
	\end{split}\end{equation*} %}
	を用いて、$\bigl(\exp(\phi_1+\phi_2)\bigr)a$によって列挙される。
	$\bigl(\exp(\phi_1+\phi_2)\bigr)$を低次の項について計算してみる。
	\begin{equation*}\begin{split} %{
		\phi_1 = \phi\left(\mytree{
			*+[o][F-]{0} \ar@{-}[d] \\
			*+[o][F-]{1}
		}\right),\quad \phi_2 = \phi\left(\mytree{
			& *+[o][F-]{0} \ar@{-}[dl] \ar@{-}[dr] \\
			*+[o][F-]{2} & & *+[o][F-]{2}
		}\right) \\
		\phi_1^2 = \phi\left(\mytree{
			*+[o][F-]{0} \ar@{-}[d] \\
			*+[o][F-]{1} \ar@{-}[d] \\
			*+[o][F-]{1}
		}\right),\quad \phi_1\phi_2 = \phi\left(\mytree{
			& *+[o][F-]{0} \ar@{-}[d] \\
			& *+[o][F-]{1} \ar@{-}[dl] \ar@{-}[dr] \\
			*+[o][F-]{2} & & *+[o][F-]{2}
		}\right) \\
		\phi_2\phi_1 = \phi\left(\mytree{
			& *+[o][F-]{0} \ar@{-}[dl] \ar@{-}[dr] \\
			*+[o][F-]{2} \ar@{-}[d] & & *+[o][F-]{2} \\
			*+[o][F-]{1}
		} + \mytree{
			& *+[o][F-]{0} \ar@{-}[dl] \ar@{-}[dr] \\
			*+[o][F-]{2} & & *+[o][F-]{2} \ar@{-}[d] \\
			& & *+[o][F-]{1}
		}\right),\quad \phi_2^2 = \left(\mytree{
			& & *+[o][F-]{0} \ar@{-}[dl] \ar@{-}[dr] \\
			& *+[o][F-]{2} \ar@{-}[dl] \ar@{-}[dr] & & *+[o][F-]{2} \\
			*+[o][F-]{2} & & *+[o][F-]{2}
		} + \mytree{
			& *+[o][F-]{0} \ar@{-}[dl] \ar@{-}[dr] \\
			*+[o][F-]{2} & & *+[o][F-]{2} \ar@{-}[dl] \ar@{-}[dr] \\
			& *+[o][F-]{2} & & *+[o][F-]{2}
		}\right) \\
	\end{split}\end{equation*} %}
	ここで、写像$\phi$は$B=\set{0,1,2}$を頂点とする木の空間$RTB$から
	$\myop{map}(RWA,RWA)$への線形写像で次のように定義される。
	\begin{equation*}\begin{split} %{
		\begin{split} %{
			\left(\phi\;\mytree{*+[o][F-]{0}}\right)f &= f \\
			\left(\phi\;\mytree{
				*+[F-]{x} \ar@{-}[d] \\
				*+[o][F-]{1}
			}\right)f &= \left(\phi\;\mytree{
				*+[F-]{x}
			}\right)b_1fc_1 \\
			\left(\phi\;\mytree{
				& *+[F-]{x} \ar@{-}[dl] \ar@{-}[dr] \\
				*+[o][F-]{2} & & *+[o][F-]{2}
			}\right)f &= \left(\phi\;\mytree{
				*+[F-]{x}
			}\right)b_2fc_2fd_2 \\
		\end{split} %}
		\quad\text{for all }f\in RWA
	\end{split}\end{equation*} %}
%s1:文脈自由と木構造}

\section{文脈自由と調和振動子}\label{s1:文脈自由と調和振動子} %{
	状態遷移
	\begin{equation*}\xymatrix{
		\ket{-\otimes0} \ar[r]^{a} \ar[d]_{c} 
		& \ket{-\otimes1} \ar[r]^{a} \ar[d]_{c}
		& \ket{-\otimes2} \ar[r]^{a} \ar[d]_{c}
		& \cdots \\
		\ket{+\otimes0}
		& \ket{+\otimes1} \ar[l]_{b}
		& \ket{+\otimes2} \ar[l]_{b}
		& \cdots \ar[l]_{b} \\
	}\end{equation*}
	で、
	\begin{itemize}\setlength{\itemsep}{-1mm} %{
		\item ボゾニックな調和振動子$\alpha,\alpha^\dag$と
		\begin{equation*}\begin{split} %{
			\alpha &= \sum_{n\in\mybf{N}}\ket{n}\bra{n+1}
		\end{split}\end{equation*} %}
		\item フェルミオニックな調和振動子$\theta,\theta^\dag$と
		\begin{equation*}\begin{split} %{
			\theta &= \ket{-}\bra{+} \\
		\end{split}\end{equation*} %}
		\item フェルミオニックな射影$\pi_-,\pi_+$
		\begin{equation*}\begin{split} %{
			\pi_{\pm} &= \ket{\pm}\bra{\pm} \\
		\end{split}\end{equation*} %}
	\end{itemize} %}
	を用いると、文法定義は$\exp\rho$と書ける。
	\begin{equation*}\begin{split} %{
		\rho = aA + bB + cC
		,\quad A = \pi_-\otimes \alpha^\dag
		,\quad B = \pi_+\otimes \alpha
		,\quad C = \theta^\dag\otimes \myid
	\end{split}\end{equation*} %}
	始状態を$\ket{-\otimes0}$、終状態を$\ket{+\otimes0}$とすると、
	\begin{equation*}\begin{split} %{
		\bra{+\otimes0}\myid\ket{-\otimes0} &= 0 \\
		\bra{+\otimes0}\rho\ket{-\otimes0} &= c \\
		\bra{+\otimes0}\rho^2\ket{-\otimes0} &= 0 \\
		\bra{+\otimes0}\rho^3\ket{-\otimes0} &= bca \\
		\vdots \\
		\bra{+\otimes0}\rho^{2n}\ket{-\otimes0} &= 0 \\
		\bra{+\otimes0}\rho^{2n+1}\ket{-\otimes0} &= b^nca^n \\
	\end{split}\end{equation*} %}
	となって、$\bra{+\otimes0}(\exp\rho)\ket{-\otimes0}$は
	文脈自由言語$\sum_{n\in\mybf{N}}b^nca^n$を定義する。
	線形微分方程式に持ち込んでこの結果を得ることもできる。
	フェルミオン部分の始状態$\ket{-}$と終状態$\ket{+}$で挟んで微分すると
	次のようになる。
	\begin{equation*}\begin{split} %{
		\partial_t \begin{pmatrix}
			\bra{+}\exp(t\rho)\ket{-} \\
			\bra{-}\exp(t\rho)\ket{-}
		\end{pmatrix} &= \begin{pmatrix}
			b\alpha & c \\
			0 & a\alpha^\dag
		\end{pmatrix}\begin{pmatrix}
			\bra{+}\exp(t\rho)\ket{-} \\
			\bra{-}\exp(t\rho)\ket{-}
		\end{pmatrix}
	\end{split}\end{equation*} %}
	この式は微分方程式
	\begin{equation*}\begin{split} %{
		\partial_tx &= bxa,\quad x0 = c
	\end{split}\end{equation*} %}
	から左再帰を除去\cite{html:wikipedia.left-recursion}したものになっている。

	調和振動子を有限$\alpha^N=0$にした場合も同様である。
	\begin{equation*}\xymatrix{
		\ket{-\otimes0} \ar[r]^{a} \ar[d]_{c} 
		& \ket{-\otimes1} \ar[r]^{a} \ar[d]_{c}
		& \ket{-\otimes2} \ar[r]^{a} \ar[d]_{c}
		& \cdots \ar[r]^{a} 
		& \ket{-\otimes N-1} \ar[d]_{c} \\
		\ket{+\otimes0}
		& \ket{+\otimes1} \ar[l]_{b}
		& \ket{+\otimes2} \ar[l]_{b}
		& \cdots \ar[l]_{b}
		& \ket{+\otimes N-1} \ar[l]_{b} \\
	}\end{equation*}
	この場合は、$\bra{+\otimes0}(\exp\rho)\ket{-\otimes0}$は
	正規言語$\sum_{0\le n<N}b^nca^n$を定義する。

	次の文法に相当する状態遷移を考える。
	\begin{equation*}\begin{split} %{
		x &= c + bxa \\
		y &= x + xdy \\
	\end{split}\end{equation*} %}
	次の状態遷移が相当するだろう。
	\begin{equation*}\xymatrix{
		\ket{-\otimes0} \ar[r]^{a} \ar[d]_{c} 
		& \ket{-\otimes1} \ar[r]^{a} \ar[d]_{c}
		& \ket{-\otimes2} \ar[r]^{a} \ar[d]_{c}
		& \cdots \\
		\ket{+\otimes0} \ar@(l,l)[u]^{d}
		& \ket{+\otimes1} \ar[l]_{b}
		& \ket{+\otimes2} \ar[l]_{b}
		& \cdots \ar[l]_{b} \\
	}\end{equation*}
	ボゾン部分の射影$\pi_n=\ket{n}\bra{n}$を用いると、文法定義は$\exp\rho$
	と書ける。
	\begin{equation*}\begin{split} %{
		\rho = aA + bB + cC + dD \\
		A = \pi_-\otimes \alpha^\dag,\quad B = \pi_+\otimes \alpha \\
		C = \theta^\dag\otimes \myid,\quad D = \theta\otimes \pi_0
	\end{split}\end{equation*} %}
	フェルミオン部分の始状態$\ket{-}$と終状態$\ket{+}$で挟んで微分すると
	次のようになる。
	\begin{equation*}\begin{split} %{
		\partial_t \begin{pmatrix}
			\bra{+}\exp(t\rho)\ket{-} \\
			\bra{-}\exp(t\rho)\ket{-}
		\end{pmatrix} &= \begin{pmatrix}
			b\alpha & c \\
			d\pi_0 & a\alpha^\dag
		\end{pmatrix}\begin{pmatrix}
			\bra{+}\exp(t\rho)\ket{-} \\
			\bra{-}\exp(t\rho)\ket{-}
		\end{pmatrix}
	\end{split}\end{equation*} %}

	次の文法を考える。
	\begin{equation*}\begin{split} %{
		x &= a + dxcxb \\
	\end{split}\end{equation*} %}
	対応する生成関数$\exp\rho$を次のようにおき、
	\begin{equation*}\begin{split} %{
		\rho = aA + bB + cC + dD
	\end{split}\end{equation*} %}
	次のような関係を設定する。
	\begin{equation*}\begin{split} %{
		AA = BA = 0,\quad CB = DB = 0 \\
		CC = DC = 0,\quad AD = BD = 0 \\
	\end{split}\end{equation*} %}
	この関係を満たす行列$A,B,C,D$を求めることができるだろうか？
	冪ゼロ性$A^2=C^2=0$から$M_2\otimes M_2\otimes W$で表現できそうに思う。
	ここで、$M_2$は$2$次元正方行列、$W$はワイル代数である。

	\subsection{うそ}\label{s2:うそ} %{
		次の状態遷移からはインデックス言語$\sum_{n\in\mybf{N}_+}b^nc^na^n$が定義
		される。
		\begin{equation*}\xymatrix@R=1pc{
			\ket{0\otimes0} \ar[r]^{a}
			& \ket{1\otimes1} \ar[r]^{a} \ar[d]_{c}
			& \ket{2\otimes2} \ar[r]^{a} \ar[d]_{c}
			& \ket{3\otimes3} \ar[r]^{a} \ar[d]_{c}
			& \cdots \\
			& \ket{0\otimes1} \ar[lu]^{b}
			& \ket{1\otimes2} \ar[d]_{c}
			& \ket{2\otimes3} \ar[d]_{c}
			\\
			& & \ket{0\otimes2} \ar[lu]^{b}
			& \ket{1\otimes3} \ar[d]_{c}
			\\
			&	&	& \ket{0\otimes3} \ar[lu]^{b}
			\\
		}\end{equation*}
		文法定義は$\exp\rho$と書ける。
		\begin{equation*}\begin{split} %{
			\rho = aA + bB + cC,\quad
			A = \alpha^\dag\otimes\alpha^\dag,\quad B = \myid\otimes\alpha
			,\quad C = \alpha\otimes\myid
		\end{split}\end{equation*} %}

		一般的な処方箋を書いておく。
		文字から代数への写像を$\rho$とすると、文法定義が$\exp\rho$となる。
		このことは表現の定義でありすべての場合に成り立つ。
		次のようにWeyleまたはHeisenberg代数と半単純Lie代数に表現を持つ場合、
		半単純Lie代数の部分の始状態と終状態を決めると、非自明な線形微分方程式が
		得られる。得られた線形微分方程式は、Fock空間内での状態遷移を表す。
		状態空間は無限次元になり得るが、線形微分方程式なので、
		\begin{itemize}\setlength{\itemsep}{-1mm} %{
			\item 先頭から一文字づつマッチングしていき、
			\item ボゾンの消滅演算子に対して$-1$、生成演算子に対して$+1$と深さを
			勘定すれば、
		\end{itemize} %}
		受理の判定は問題無く行える。
		\begin{equation*}\begin{split} %{
			\rho &= \sum_{a\in A}a\biggl(
				\underbrace{W_{a1}\otimes W_{a2}\otimes\cdots\otimes W_{a_m}}
				_{WeyleまたはHeisenberg代数}
				\otimes\underbrace{L_{a1}\otimes L_{a2}\otimes\cdots\otimes L_{a_n}}
				_{半単純Lie代数}
				\biggr)
		\end{split}\end{equation*} %}
	%s2:うそ}
%s1:文脈自由と調和振動子}

\section{文字列の普遍性の使い方その一}\label{s1:文字列の普遍性の使い方その一} %{
	$A$を有限集合、$WA=(WA,m_*,1_W)$を文字列の連結$m_*$を積、文字数0の単語
	$1_W$を単位元とするモノイドとする。$A$から$WA$への標準入射を$i_W$とする。
	$\Lambda A=(WA\cup\set{0},m_\land,1_\land)$をゼロ元$0$を持つモノイドとし、
	積$m_\land$を次のように定義する。
	\begin{equation*}\begin{split} %{
		m_\land(w_1\times w_2) &= \jump{w_1=w_2}w_2
		\quad\text{for all }w_1,w_2\in WA
	\end{split}\end{equation*} %}
	積$m_\land$に対する単位元は$1_\land=\sum_{w\in WA}$となる。
	自由モノイドの普遍性により、次の可換図を可換にする$\phi_\Lambda$が唯一つ
	定まり、任意の写像$f:A\to\Lambda A$に対して$\phi_\Lambda f$はモノイド射
	となる。
	\begin{equation*}
		\xymatrix{
			A \ar[rd]_{f} \ar[r]^{i_W} & WA \ar[d]^{\phi_\Lambda f} \\
			& \Lambda A
		}\quad\text{for all }f\in \mapset(A,\Lambda A) \\
	\end{equation*}
	写像$i_\Lambda:A\to \Lambda A$を
	$i_\Lambda a=[a]$とすると、$\phi_\Lambda i_\Lambda$は次のようになる。
	\begin{equation*}\begin{split} %{
		(\phi_\Lambda i_\Lambda)1_W &= 1_\Lambda \\
		(\phi_\Lambda i_\Lambda)[a_1a_2\cdots a_m] 
		&= \jump{a_1=a_2=\cdots=a_m}[a_m] \\
		&\quad\text{for all }a_1,a_2,\dots,a_m\in A \\
	\end{split}\end{equation*} %}
	したがって、$(\phi_\Lambda i_\Lambda)WA\simeq(i_\Lambda A)\cup\set{0}$
	となることがわかる。
%s1:文字列の普遍性の使い方その一}

\section{いっぱい環}\label{s1:いっぱい環} %{
	自然数$\mybf{N}$からor-andブーリアン$\mybf{B}$への写像$f$を次のように
	定義する。
	\begin{equation*}\begin{split} %{
		fm = \jump{m\neq0} \quad\text{for all }m\in\mybf{N}
	\end{split}\end{equation*} %}
	すると、次の可換図が成り立ち、$f$は半環準同型になるこことがわかる。
	\begin{equation*}\xymatrix@C+2pc{
		m_1\times m_2 \ar[r]^{m_+} \ar[d]^{f\times f} 
		& m_1+m_2 \ar[d]^{f} \\
		\jump{m_1\neq0}\times \jump{m_2\neq0} \ar[r]^{m_\lor}
		& \jump{m_1\neq0}\lor\jump{m_2\neq0}=\jump{m_1+m_2\neq0}
	}\end{equation*}
	\begin{equation*}\xymatrix@C+2pc{
		m_1\times m_2 \ar[r]^{m_\myspace} \ar[d]^{f\times f} 
		& m_1m_2 \ar[d]^{f} \\
		\jump{m_1\neq0}\times \jump{m_2\neq0} \ar[r]^{m_\land}
		& \jump{m_1\neq0}\land\jump{m_2\neq0}=\jump{m_1m_2\neq0}
	}\end{equation*}
	したがって、自然数を係数とする半モジュールで作られた理論はそのまま
	or-andブーリアンを係数とする理論に移行できると思われる。
	逆の写像$\mybf{B}\to\mybf{N}$では半環準同型は多分存在しない。
	したがって、or-andブーリアンを係数とする半モジュールで作られた理論
	は自然数を係数とする理論へ移行することはできないと思われる。

	or-andブーリアンは$\set{0,1=\text{いっぱい}}$とみることができる。
	これを拡張して、$2\le n\in\mybf{N}$に対して、
	$\myop{Max}_n=\set{0,1,n-1=\text{いっぱい}}$を考えてみる。
	$\myop{Max}_n$に演算$+_n$と$\myspace_n$を次のように定義する。
	\begin{equation*}\begin{split} %{
		p\square_nq=\myop{max}_n(p\square q)
		\quad\text{for all }p,q\in\myop{Max}_n,\;\square\in \set{+,\myspace}
	\end{split}\end{equation*} %}
	ここで、$\myop{max}_np=\max(n\times p)$とした。
	可換図で書くと、射影$\pi_n:\mybf{N}\to\myop{Max}_n$と
	埋め込み$\iota_n:\myop{Max}_n\to\mybf{N}$
	\begin{equation*}\begin{split} %{
		\pi_n p &= \myop{max}_np \quad\text{for all }p\in \mybf{N} \\
		\iota_n p &= p \quad\text{for all }p\in \myop{Max}_n \\
	\end{split}\end{equation*} %}
	を使って、次のような畳み込みで$\square_n$を定義したことになる。
	\begin{equation*}\xymatrix@C+1pc{
		\mybf{N}\times \mybf{N} \ar[d]^{\myhere\square\myhere}
			& \myop{Max}_n\times \myop{Max}_n 
			\ar@{.>}[d]^{\myhere\square_n\myhere}
			\ar[l]_{\iota_n\times \iota_n} \\
		\mybf{N} \ar[r]^{\pi_n} & \myop{Max}_n
	}\end{equation*}
	$\square_n$は畳み込みで定義されているから結合的になることはわかる。
	加法$+_n$に関しては次のようになり、$\pi_n$がモノイド準同型となることが
	わかる。
	\begin{equation*}\begin{split} %{
		(\myop{max}_np)+_n(\myop{max}_nq) &= \begin{cases}
			p+q, &\text{ if }p+q\le n \\
			\myop{max}_n(n+n) = n &\text{ else }n\le p\text{ and }n\le q \\
			\myop{max}_n(n+q) = n &\text{ else }n<p\text{ and }q<n  \\
			\myop{max}_n(p+n) = n &\text{ else }p<n\text{ and }n<q  \\
			\myop{max}_n(p+q) = n &\text{ otherwise }(p<n\text{ and }q<n) \\
		\end{cases} \\
		&= \myop{max}_n(p+q) \quad\text{for all }p,q\in\mybf{N}
	\end{split}\end{equation*} %}
	乗法$\myspace_n$に関しては次のようになり、$\pi_n$がモノイド準同型となる
	ことがわかる。
	\begin{equation*}\begin{split} %{
		(\myop{max}_np)\myspace_n(\myop{max}_nq) &= \begin{cases}
			pq, &\text{ if }pq\le n \\
			\myop{max}_n(n^2) = n &\text{ else }n\le p\text{ and }n\le q \\
			\myop{max}_n(nq) = \jump{0<q}n &\text{ else }n<p\text{ and }q<n  \\
			\myop{max}_n(pn) = \jump{0<p}n &\text{ else }p<n\text{ and }n<q  \\
			\myop{max}_n(pq) = n &\text{ otherwise }(p<n\text{ and }q<n) \\
		\end{cases} \\
		&= \myop{max}_n(pq) \quad\text{for all }p,q\in\mybf{N}
	\end{split}\end{equation*} %}
	したがって、射影$\pi_n$が半環準同型となることがわかる。
%s1:いっぱい環}

\section{一見して同じとわからない正規表現}\label{s1:一見して同じとわからない正規表現} %{
	or-andブーリアン係数では、次の異なる二つのBNFは同一の正規表現$(ab)^*a$
	を与えているように見える。
	\begin{equation*}\begin{split} %{
		x = a + abx,\quad y = a + yby
	\end{split}\end{equation*} %}
	$x$に関しては次のようになり、$x=(ab)^*a$とわかる。
	\begin{equation*}\begin{split} %{
		(1-ab)x=a \implies x = \frac{1}{1-ab}a = (ab)^*a
	\end{split}\end{equation*} %}
	$y$に関しては次のようになる。
	\begin{equation*}\begin{split} %{
		y=a+(a+yby)b(a+yby)=a+aba+abyby+ybyba+ybybyby
	\end{split}\end{equation*} %}
	$x=y$だとすると、次の式が成り立つ。
	\begin{equation*}\begin{split} %{
		a+ab(ab)^*a = (ab)^*a = a+(ab)^*ab(ab)^*a
	\end{split}\end{equation*} %}
	したがって、次の式が成り立つ。
	\begin{equation*}\begin{split} %{
		1+ab(ab)^* = (ab)^* = 1+(ab)^*ab(ab)^*
	\end{split}\end{equation*} %}
	一般化すると、次の式が成り立つ。
	\begin{equation*}\begin{split} %{
		1+xx^* = x^* = 1+x^*xx^*
	\end{split}\end{equation*} %}
	冪等ブーリアンだと、$(x^*)^2=x^*$が成り立つのではないだろうか？
	冪等性を仮定せずに計算してみる。
	\begin{equation}\label{eq:ハミルトニアンに相似な式}\begin{split} %{
		(f^*)^2 &= (1+ f + f^2 + \cdots)^2 \\
		&= 1 + (1f+f1) + (1f^2+ff+f^21) \\
		&\;+ (1f^3+ff^2+f^2f+f^31) + \cdots \\
		&= 1 + 2f + 3f^2 + 4f^3 + \cdots \\
		&= \sum_{k\in\mybf{N}}(k+1)f^k \quad\text{for all }f\in \mybf{C}WA
	\end{split}\end{equation} %}
	確かに冪等ブーリアンだと、$(x^*)^2=x^*$が成り立つ。
	したがって、最初の問題、
	\begin{itemize}\setlength{\itemsep}{-1mm} %{
		\item 次の$x$と$y$は等しいか？
		\begin{equation*}\begin{split} %{
			x &= a + (ab)^*x \\
			y &= a + yby \\
		\end{split}\end{equation*} %}
	\end{itemize} %}
	という問題に対する解答は得られて、次のような答えになる。
	\begin{itemize}\setlength{\itemsep}{-1mm} %{
		\item 冪等ブーリアン係数であれば、$((ab)^*)^2=(ab)^*$が成り立つから
		$x$と$y$は等しい。
		\item さらに、次の式も成り立つ。
		\begin{equation*}\begin{split} %{
			x &= (ab)^*a \\
			&= a + abx \\
			&= a + xbx \\
			&= a + xbx + xbxbx \\
			&= \cdots \\
		\end{split}\end{equation*} %}
	\end{itemize} %}

	式\eqref{eq:ハミルトニアンに相似な式}のべき乗を一般化してみる。
	単語の連結積$m$とその転置$\Delta$を用いると次のようになる。
	\begin{equation}\label{eq:単語に対するハミルトニアンを用いた式}\begin{split} %{
		(a^*)^{n+1} &= (1+ a + a^2 + \cdots)^{n+1} \\
		&= \sum_{k\in\mybf{N}}m^n\Delta^na^k
		\quad\text{for all }a\in A,\;n\in\mybf{N}
	\end{split}\end{equation} %}
	余積$\Delta^n$は与えられた単語を$n+1$個の単語に分割する方法の列挙である。
	$\Delta^na^k$は$(1+a+a^2+\cdots+a^k)^{n+1}$から$a^k$の項をピックアップ
	する方法の列挙に対応する。

	式\eqref{eq:単語に対するハミルトニアンを用いた式}に線形写像
	$f:\mybf{C}A\to \mybf{C}WA$から誘導される代数射
	$f_*:\mybf{C}WA\to\mybf{C}WA$
	\begin{equation*}\begin{split} %{
		f_*1_W &= 1_W \\
		f_*[a_1a_2\cdots a_m] &= (fa_1)(fa_2)\cdots(fa_m)
		\quad\text{for all }a_1,a_2,\dots,a_m\in A \\
	\end{split}\end{equation*} %}
	を適用すると、$m^n\Delta^n[a^k]=([a^k]^\dag m^n\Delta^n[a^k])[a^k]$となる
	ことに注意して、次のようになる。
	\begin{equation*}\begin{split} %{
		f_*\bigl([a]^*\bigr)^{n+1} &= \bigl((fa)^*\bigr)^{n+1} \\
		&= \sum_{k\in\mybf{N}}\bigl([a^k]^\dag m^n\Delta^n[a^k]\bigr)(fa)^k
		\quad\text{for all }a\in A,\;n\in\mybf{N} \\
	\end{split}\end{equation*} %}
	したがって、式\eqref{eq:単語に対するハミルトニアンを用いた式}を一般化した
	次の式が成り立つ。
	\begin{equation*}\begin{split} %{
		(f^*)^{n+1} 
		&= \sum_{k\in\mybf{N}}c^{n+1}_kf^k
		\quad\text{for all }f\in\mybf{C}WA,\; n\in\mybf{N} \\
		c^{n+1}_k
		&= [a^k]^\dag m^n\Delta^n[a^k]
		\quad\text{for all }a\in A,\; n\in\mybf{N},\;k\in\mybf{N} \\
	\end{split}\end{equation*} %}
	ここで、定数$c^{n+1}_k$を定めるために使われている$[a^k]$は長さ$k$の単語
	であれば何でもよい。任意の長さ$k$の単語$w_1,w_2\in W_kA$に対して
	$w_1^\dag m^n\Delta^nw_1=w_2^\dag m^n\Delta^nw_2$が成り立つ。
	定数を漸化式のかたちで求めると、次の式より、
	\begin{equation*}\begin{split} %{
		c^{n+1}_k &= [a^k]^\dag m^{n+1}\Delta^{n+1}[a^k]
		\\
		&= \sum_{\substack{k_1,\dots,k_{n+1},k_{n+2}\in\mybf{N} \\
			k_1+\cdots+k_{n+1}+k_{n+2}=k
		}} [a^k]^\dag m^{n+1}\bigl(
			[a^{k_1}]\otimes\cdots\otimes[a^{k_{n+1}}]\otimes[a^{k_{n+2}}]
		\bigr)
		\\
		&= \sum_{k_{n+2}=0}^k \sum_{\substack{k_1,\dots,k_{n+1}\in\mybf{N} \\
			k_1+\cdots+k_{n+1}=k-k_{n+2}
		}} [a^k]^\dag m\biggl([a^{k_{n+2}}]\otimes
			m^n\bigl([a^{k_1}]\otimes\cdots\otimes[a^{k_{n+1}}]\bigr)\biggr)
		\\
		&= \sum_{k_{n+2}=0}^k [a^{k-k_{n+2}}]^\dag m^n\Delta^n[a^{k-k_{n+2}}]
		\\
		&= \sum_{l=0}^k c^n_l \quad\text{for all }n,k\in\mybf{N},\;a\in A
	\end{split}\end{equation*} %}
	次の漸化式が求まる。
	\begin{equation*}\begin{split} %{
		c^0_k &= 1 \quad\text{for all }k\in\mybf{N} \\
		c^{n+1}_k &= \sum_{l=0}^k c^n_l \quad\text{for all }n,k\in\mybf{N}
	\end{split}\end{equation*} %}
%s1:一見して同じとわからない正規表現}

\section{領域分割のパターン}\label{s1:領域分割のパターン} %{
	集合$X$から集合$Y$への写像$f$が与えられたとき、写像$f$を分割していって、
	$f$の計算をより簡単な計算に帰着させることがよく行われる。
	写像$f$を簡単にすること以外にも、計算機での処理における並列化でも$f$を
	分割することが使われる。写像$f$を分割することを可換図で書くと
	次のようになるだろう。
	\begin{equation*}\begin{split} %{
		\xymatrix@C+4pc{
			X\times X \ar[d]^{fの分割}
				& X \ar[l]_{\text{定義域の分割}} \ar[d]^{f} \\
			Y\times Y \ar[r]^{\text{値域の合成}} & Y \\
		}
	\end{split}\end{equation*} %}
	写像$f$を計算するために、このような可換図を利用することを
	'領域分割のパターン'ということにする。

	$RA$の積$m$と余積$\Delta$から畳み込みによって$\myop{end}(RA)$に
	積と余積を定義することができる。
	\begin{equation*}\begin{split}
		\xymatrix{
			RA\otimes RA \ar[d]^{f_1\otimes f_2} 
				& RA \ar[l]_{\Delta} \ar@{.>}[d]^{\widehat{m}(f_1\otimes f_2)} \\
			RA\otimes RA \ar[r]^{m} & RA  \\
		} \xymatrix{
			RA\otimes RA \ar[r]^{m} \ar@{.>}[d]^{\widehat{\Delta}f} 
				& RA \ar[d]^{f} \\
			RA\otimes RA & RA \ar[l]_{\Delta} \\
		}
	\end{split}\end{equation*}
	そして、$m\Delta$が$0$固有値を持たなければ、$(m\Delta)^{-1}$が定義
	できて、領域分割のパターンを定義できる。
	\begin{equation*}\begin{split}
		\xymatrix{
			RA\otimes RA \ar[r]^{m} \ar[d]^{\widehat{\Delta}f} 
				& RA \ar[d]^{f} \\
			RA\otimes RA \ar[rd]_{m} & RA \ar[l]_{\Delta} \ar[d]^{m\Delta} \\
			& RA \\
		}	= \xymatrix@C+2pc{
			RA\otimes RA \ar[r]^{m} \ar[d]^{\widehat{\Delta}f}
				& RA \ar[d]^{f} \\
			RA\otimes RA \ar[r]^{(m\Delta)^{-1}m} & RA \\
		}
	\end{split}\end{equation*}
	$f\in\myop{end}(RA)$の計算するのに余積$\widehat{\Delta}f$が利用できる
	可能性が出てくる。もちろん、余積$\widehat{\Delta}f$がなんらかのかたちで
	問題を小さくしていくものであるときのみ有効は方法である。
	作用素$m\Delta$の例を挙げてみる。
	\begin{itemize}\setlength{\itemsep}{-1mm} %{
		\item $A$が自然数、積$m$が自然数の乗法、余積$\Delta$が積$m$の転置
		の場合、$m\Delta$は'含んでいる素数の数'なので、$(m\Delta)^{-1}$が
		定義できるが、その計算は困難である。また、余積$\Delta$は本質的には
		素因数分解なので、余積の計算そのものも困難である。
		\item $A$が文字列、積$m$が文字列の連結、余積$\Delta$が積$m$の転置
		の場合、$m\Delta$は'文字数+1'なので、$(m\Delta)^{-1}$が定義できて、
		その計算は容易である。
		\item $A$が群、積$m$が群の積、余積$\Delta$が積$m$の転置の場合、
		$m\Delta$は'群の大きさ'なので、群が有限の場合は、$(m\Delta)^{-1}$が
		定義できて、その計算は容易である。
	\end{itemize} %}
%s1:領域分割のパターン}

\section{*半環}\label{s1:*半環} %{
	\begin{definition}[*半環]\label{def:*半環} %{
		$R$を半環とする。$R$が次の性質をもつ逆順半環準同型写像$\myhere^*:R\to R$
		を持つとき、$R$を*半環という。
		\begin{itemize}\setlength{\itemsep}{-1mm} %{
			\item 逆順半環準同型
			\begin{equation*}\begin{split} %{
				(r_1+r_2)^* = r_1^*+r_2^*,\quad (r_1r_2)^* = r_2^*r_1^*
				\quad\text{for all }r_1,r_2\in R
			\end{split}\end{equation*} %}
			\item 反転性 $1^*=1$
			\item 冪等性 $(r^*)^*=1 \quad\text{for all }r\in R$
		\end{itemize} %}
	\end{definition} %def:*半環}
%s1:*半環}

\section{双対の圏論的側面}\label{s1:双対の圏論的側面} %{
	代数では次の二つの双対が現れる。
	\begin{itemize}\setlength{\itemsep}{-1mm} %{
		\item 代数的な双対
		\begin{equation*}\begin{split} %{
			\homset(X_1\otimes X_2, X_3)\simeq\homset(X_1,\homset(X_2,X_3))
		\end{split}\end{equation*} %}
		\item 内積による双対
		\begin{equation*}\begin{split} %{
			\homset(X_1\otimes X_2, X_3)\simeq\homset(X_3,X_2\otimes X_1))
		\end{split}\end{equation*} %}
	\end{itemize} %}
%s1:双対の圏論的側面}

\section{群のホップ代数}\label{s1:群のホップ代数} %{
	教科書\cite{bk:jinbo.ryousigun}に載っている例を使って、アンチポードの
	意味を考える。

	群$G=(G,m_\myspace,1_G)$から$K=\mybf{C}$への
	写像$KG^t\simeq \mapset(G,K)$を考える。まずは、$G$を基底とする$K$係数
	の自由ベクトル$KG$の積と余積を構成する。
	$G$の積$m_\myspace$をそのまま$R$線形に拡張して$KG$の積とする。
	$G$の余積$\delta$を$\delta x=x\otimes x$と定義する。
	群的な余積は任意の積と双対になるので、$\delta$は$G$の積$m_\myspace$
	と双対である。$G$の余積$\delta$をそのまま$R$線形に拡張して$KG$の余積
	とする。
	$\delta$は任意の$x\in G$に対して$\zeta x=1$となる定数写像である。

	余積$\Delta_*$を$m_\myspace$の転置となるように定める。
	\begin{equation*}\begin{split} %{
		(\Delta_*x)^t(x_1\otimes x_2) &\simeq x^t(x_1x_2)
			\quad\text{for all }x,x_1,x_2\in G \\
		\Delta_*x &= \sum_{x_1,x_2\in G}\jump{x=x_1x_2}x_1\otimes x_2
			\quad\text{for all }x\in G \\
	\end{split}\end{equation*} %}
	すると、$f=\sum_{x\in G}f_xx\in KG$に対して次のようになる。
	\begin{equation*}\begin{split} %{
		(\Delta_*f)^t(x_1\otimes x_2) 
		&= \sum_{x\in G}f_x(\Delta_*x)^t(x_1\otimes x_2) \\
		&= \sum_{x\in G}f_{x_1x_2}1\otimes 1 \\
		&= f^t(x_1x_2)\otimes 1
	\end{split}\end{equation*} %}
	$m_\myspace$が結合的だから、$m_\myspace$の転置である余積$\Delta_*$は
	余結合的になる。
	$1_G^t$は、
	\begin{itemize}\setlength{\itemsep}{-1mm} %{
		\item $\Delta_*1_G=1_G\otimes1_G$だから、$KG$から$K$への代数射となり、
		\item 次の式を満たすから、
			\begin{equation*}\begin{split} %{
				(1_G^t\otimes \myid)\Delta_*x = 1\otimes x \simeq x \\
				(\myid\otimes 1_G^t)\Delta_*x = 1\otimes x \simeq x \\
			\end{split}\end{equation*} %}
	\end{itemize} %}
	余積$\Delta_*$の余単位射をとなる。

	積$m_*$は余積$\delta$の転置となるように定める。
	\begin{equation*}\begin{array}{ll} %{
		(x_1*x_2)^tx = (x_1^tx)(x_2^tx) \simeq (x_1\otimes x_2)^t\delta x
			& \quad\text{for all }x,x_1,x_2\in G \\
		x_1*x_2 = \jump{x_1=x_2}x_2
			& \quad\text{for all }x_1,x_2\in G \\
	\end{array}\end{equation*} %}
	すると、$f_i=\sum_{x\in G}f_{ix}x\in KG,\;i=1,2$に対して次のようになる。
	\begin{equation*}\begin{split} %{
		(f_1*f_2)^tx 
		= \sum_{x_1,x_2\in G}\jump{x_1=x_2}f_{1x_1}f_{2x_2}(x_1^tx)(x_2^tx)
		= (f_1^tx)(f_2^tx)
	\end{split}\end{equation*} %}
	積$m_*$の単位元$1_*$は余積$\delta$の余単位射$\zeta$（
	$\zeta x=1\quad\text{for all }x\in G$）を転置したものになっている。
	転置を使って$\zeta=\sum_{x\in G}x^t$と書けるから、
	$1_*=\sum_{x\in G}x$と書け、$\zeta=1_*^t$となる。

	まとめると表\ref{table:群の双代数}のようになる。
	\begin{table}[htbp]
		\begin{center}\begin{tabular}{cccc} \hline
			演算 & 単位 & 可換性 & 双対関係	\\ \hline
			群の積$m_\myspace$ & $1_G$ & 非可換 & $\delta$ \\
			群的余積$\delta$ & $1_*^t$ & 可換 & $m_\myspace$と$m_*$ \\
			積$m_*\simeq\delta^t$ & $1_*=\sum_{x\in G}x^t$ & 可換 
				& $\Delta_*$と$\delta$ \\
			余積$\Delta_*=m_\myspace^t$ & $1_G^t$ & 非可換 & $m_*$ \\
		\end{tabular}\end{center}
		\caption{群の双代数}\label{table:群の双代数}
	\end{table}

	教科書\cite{bk:jinbo.ryousigun}にしたがって、アンチポードを導入する。
	今までの話では$G$が群であることを使っていない。
	$G$がモノイドでもすべて事柄が成り立つ。
	アンチポードは$G$が群であることの性質を使って定義される。
	まず、$G$が群だから次の式がなりたつ。
	\begin{equation}\label{eq:群のアンチポードの定義式}\begin{split} %{
		f^t(x^{-1}x) = f^t1_G = f^t(xx^{-1})
		\quad\text{for all }x\in G,\; f\in KG
	\end{split}\end{equation} %}
	そして、トリッキーな次の式
	\begin{equation*}\begin{split} %{
		x = x1_*^ty \quad\text{for all }x,y\in G
	\end{split}\end{equation*} %}
	を使うと、次の式が成り立ち、
	\begin{equation*}\begin{split} %{
		f^t1_G = f^t1_G1_*^t x = (1_*1_G^tf)^t x 
			\quad\text{for all }x\in G,\; f\in KG
	\end{split}\end{equation*} %}
	さらに、内積の対称性
	\begin{equation*}\begin{split} %{
		x_1^tx_2^{-1} = (x_1^{-1})^tx_2 \quad\text{for all }x_1,x_2\in G
	\end{split}\end{equation*} %}
	から、逆元をとる操作$\myhere^{-1}$を$R$線形に$G$から$KG$に拡張すると、
	次の式が成り立つから、
	\begin{equation*}\begin{split} %{
		f^t(x^{-1}x) &= m_\myspace(\Delta_*f)^t(x^{-1}\otimes x) \\
		&= m_\myspace\bigl((\myhere^{-1}\otimes\myid)\Delta_*f\bigr)^t
			(x\otimes x) \\
		&= m_\myspace\bigl((\myhere^{-1}\otimes\myid)\Delta_*f\bigr)^t
			\delta x \\
		&= \bigl(m_*(\myhere^{-1}\otimes\myid)\Delta_*f\bigr)^tx \\
		&\quad\text{for all }x\in G,\;f\in KG
	\end{split}\end{equation*} %}
	最終的に次の式が成り立つ。
	\begin{equation*}\begin{split} %{
		(1_*1_G^tf)^tx_1
		= \bigl(m_*(\myhere^{-1}\otimes\myid)\Delta_*f\bigr)^tx_2 
		\quad\text{for all }x_1,x_2\in G,\; f\in KG
	\end{split}\end{equation*} %}
	この式から次のアンチポードの定義式の半分が導かれる。
	\begin{equation*}\begin{split} %{
		u\epsilon = m(S\otimes\myid)\Delta 
		\quad\text{in this case }\begin{cases} %{
			u &= 1_* \\
			\epsilon &= 1_G^t \\
			S &= \myhere^{-1} \\
			\Delta &= \Delta_* \\
		\end{cases} %}
	\end{split}\end{equation*} %}

	ここまで、形式的な計算だけを行ってきたが、体$K$が複素数$\mybf{C}$で、
	群$G$が無限群のとき、$1_*=\sum_{x\in G}x$だから、
	$1_*^t1_*=1+1+\cdots=\infty$となって、ベクトル$1_*$はすべての成分が有限
	であるにも関わらずノルムが発散する。体$K$が有限体の場合もしくは群$G$が
	有限群の場合は、こうした発散の問題はない。問題が出るのは、体$K$と群$G$
	が共に無限の場合である。

	\begin{example}[リー環の場合]\label{eg:リー環の場合} %{
		群から一次の微分をとればリー環になる。
		$G$の元をリー環で$\exp tX$と書くと、余積$\delta$は次のようになる。
		\begin{equation*}\begin{split} %{
			\delta \exp tX &= (\exp tX)\otimes(\exp tX) \\
			&\sim (1_G+tX)\otimes(1_G+tX) \\
			&\sim 1_G\otimes X + X\otimes 1_G \\
		\end{split}\end{equation*} %}
		$\delta$の余単位射は$1_G^t$となる。
		これは、群の場合の余単位射$\sum_{x\in G}x^t$からリー環の普遍包絡環の
		中に残った唯一の群元$1_G$の部分のみが生き残った形になっている。
		また、アンチポード$S$は$SX=-X,\;S1_G=1_G$となる。
		以上より、リー環の場合のアンチポードの式は次のようになる。
		\begin{equation*}\begin{split} %{
			u\epsilon = m(S\otimes\myid)\Delta
			\quad\text{in Lie algebra case }\begin{cases} %{
				u &= 1_G \\
				\epsilon &= 1_G^t \\
				S &= X^n\mapsto (-1)^nX^n \quad\text{for all }n\in \mybf{N} \\
				\Delta &= \Delta_* \\
			\end{cases} %}
		\end{split}\end{equation*} %}
	\end{example} %eg:リー環の場合}

	\begin{todo}[群の因数分解の列挙]\label{todo:群の因数分解の列挙} %{
		任意の$x\in G$に対して次の式が成り立つか？
		\begin{equation*}\begin{split} %{
			\sum_{x_1,x_2\in G}\jump{x=x_1x_2}x_1\otimes x_2
			= \sum_{y\in G}(xy)\otimes y^{-1}
		\end{split}\end{equation*} %}
		成り立てば、$\Delta_*x=\sum_{y\in G}(xy)\otimes y^{-1}$となる。
	\end{todo} %todo:群の因数分解の列挙}
%s1:群のホップ代数}

\section{Duchampによる解説}\label{s1:Duchampによる解説} %{
	Duchanmp等によるレビュー\cite{arxiv:0912.3866}がわかり易い。
	内積の観点から代数的な概念を説明している。
	$(RWA^t\otimes RWA^t)\subseteq (RWA\otimes RWA)^t$（発散の問題？）から、
	余積の転置がいつでもできることに対して、積の転置はできるとは限らない
	そうだ。
	\begin{equation*}\begin{split} %{
		\Delta\in\set{RWA\to RWA\otimes RWA} &\xrightarrow{\myhere^t} 
			\Delta^t\in\set{(RWA\otimes RWA)^t\to RWA^t} \\
		m\in\set{RWA\otimes  RWA\to RWA} &\xrightarrow{\myhere^t} 
			m^t\in\set{RWA^t\to (RWA\otimes RWA)^t} \\
	\end{split}\end{equation*} %}
	$\Delta^t$は定義域を$RWA^t\otimes RWA^t$に制限すればよいのに対して、
	$m^t$は値域が$RWA^t\otimes RWA^t$をはみ出てしまうので対処できない
	ということらしい。

	無限の問題について、Duchanmp等による別の論文\cite{arxiv:0712.0125}
	にある例を見てみる。積と双対になっていない余積に起こり得る現象の例
	である。余積$\Delta:\mybf{Q}[x]\to\mybf{Q}[x]\otimes\mybf{Q}[x]$を
	次のように定義\footnote{
		論文\cite{arxiv:0712.0125}では
		$\Delta:x\mapsto \frac{1}{n!}(x^n\otimes x^n)$ なっているが、
		タイプミスだろう。
	}し、
	\begin{equation*}\begin{split} %{
		x^n &\mapsto \frac{1}{n!}(x^n\otimes x^n) 
			\quad\text{for all }n\in\mybf{N}
	\end{split}\end{equation*} %}
	その内積$(x^m)^tx^n=\jump{m=n}$に関する双対$\Delta^t$を求めると、
	\begin{equation*}\begin{split} %{
		(\Delta x^m)^t(x^p\otimes x^q) 
			&= \frac{1}{m!}(x^m\otimes x^m)^t(x^p\otimes x^q) \\
			&= \frac{1}{m!}\jump{p=q=m}(1\otimes 1) \\
			&\simeq (x^m)^t\bigl(\Delta^t(x^p\otimes x^q)\bigr) \\
	\end{split}\end{equation*} %}
	より、次のようになり、
	\begin{equation*}\begin{split} %{
		\Delta^t(x^p\otimes x^q) &= \jump{p=q}\frac{1}{p!}
		\quad\text{for all }p,q\in \mybf{N}
	\end{split}\end{equation*} %}
	$\frac{1}{1-x}\in \mybf{Q}[x]$の二乗を求めると次のようになって、
	$\mybf{Q}[x]$をはみ出て$\mybf{R}[x]$に飛び出してしまう。
	\begin{equation*}\begin{split} %{
		\Delta^t(\frac{1}{1-x}\otimes \frac{1}{1-x}) = \exp x \not\in \mybf{Q}[x] \\
	\end{split}\end{equation*} %}
%s1:Duchampによる解説}

\section{超対称性}\label{s1:超対称性} %{
	無限次元ベクトル空間が有限次元の場合とは異なる振る舞いをする例として、
	簡単な超対称性モデルを書いておく。

	$V$を複素数$\mybf{C}$を係数とするベクトル空間、$Q\in\myop{end}V$を
	冪ゼロ$Q^2=0$な作用素、$N_F\in\myop{end}V$を$N_FQ=Q(N_F+1)$となる
	エルミート$N_F^\dag=N_F$な作用素とする。$N_F$はエルミートだから固有値は
	実数になる。$N_F$の固有値$\lambda$に属する固有ベクトル$v$に対して、
	$N_FQv=Q(N_F+1)v=(\lambda+1)Qv$となるから、$Qv$は$N_F$の固有値$\lambda+1$
	を持つ。$N_F$が自然数に固有値を持つとする。
	すると、$N_F$の固有値$n\in\mybf{N}$を持つ固有ベクトルで張られる空間を
	$V_n$として、$V=\oplus_{n\in\mybf{N}}V_n$と書け、任意の$n\in\mybf{N}$
	に対して$Q:V_n\to V_{n+1}$となる。エルミートな作用素$H=QQ^\dag+Q^\dag Q$
	を考える。$H$はエルミートで$Q$の二乗だからその固有値は$0$以上の実数値に
	なる。$Q$と$H$は可換になり、$N_F$と$H$も可換になる。
	特に、$N_F$と$H$は共にエルミートな作用素なので同時対角化が可能である。
	$H$の固有値$\lambda$に属する固有ベクトル$v\neq0$に対して次のことが
	成り立つ。
	\begin{itemize}\setlength{\itemsep}{-1mm} %{
		\item $Qv\neq0$なら、$Qv$も$H$の固有値$\lambda$を持ち、
		$0<\lambda$となる。
		\begin{proof} %{
			\begin{equation*}\begin{split} %{
				HQv=QHv=\lambda Qv,\quad HQ^\dag v=Q^\dag Hv=\lambda Q^\dag v
			\end{split}\end{equation*} %}
			となるから、$Qv\neq0$なら、$Qv$も$H$の固有値$\lambda$を持つ。
			任意の$w\in V$に対してその二乗ノルムを$\zettai{w}^2=w^\dag w$と書く
			と、$Hv=\lambda v$だから、
			$\lambda\zettai{v}^2=v^\dag Hv=\zettai{Qv}^2+\zettai{Q^\dag v}^2$
			が成り立ち、次の不等式が成り立つ。
			\begin{equation*}\begin{split} %{
				0 < \frac{\zettai{Qv}^2}{\zettai{v}^2} \le \lambda
					= \frac{\zettai{Qv}^2+\zettai{Q^\dag v}^2}{\zettai{v}^2}
			\end{split}\end{equation*} %}
		\end{proof} %}
		\item $Qv=0$なら、$Q^\dag v=0$となり、$0=\lambda$となる。
		\begin{proof} %{
			$Qv=0$と$Hv=0$から$QQ^\dag v=0$となるが、
			$0=v^\dag QQ^\dag v=\zettai{Q^\dag v}^2$となり、$Q^\dag v=0$となる。
		\end{proof} %}
	\end{itemize} %}
	$Q$と$Q^\dag$は対称的なかたちで$H$に入っているから、次のことも成り立つ。
	\begin{itemize}\setlength{\itemsep}{-1mm} %{
		\item $Q^\dag v\neq0$なら、$Q^\dag v$も$H$の固有値$\lambda$を持ち、
		$0<\lambda$となる。
		\item $Q^\dag v=0$なら、$Q^\dag v=0$となり、$0=\lambda$となる。
	\end{itemize} %}
	したがって、すべての$n\in\mybf{N}$で、$V_n$における$H$の$0$以外の固有値
	の分布は一致する。$H$の$0$以外の固有値の分布を$\myop{eigen}_+H$とすると、
	すべての$n\in\mybf{N}$で$V_n$は次のように分解される。
	\begin{equation*}\begin{split} %{
		V_n = V_n^0\oplus \sum_{\lambda\in\myop{eigen}_+H}V_n^\lambda
		,\quad \begin{array}{ll}
			Hv = 0 &\quad\text{for all }v\in V_n^0 \\
			Hv = \lambda v &\quad\text{for all }v\in V_n^\lambda \\
		\end{array} \\
		\begin{array}{rrcl}
			Q :& V_n^\lambda &\to& V_{n+1}^\lambda \\
			Q^\dag :& V_{n+1}^\lambda &\to& V_n^\lambda
			\end{array} \quad\text{for all }\lambda\in\myop{eigen}_+H
	\end{split}\end{equation*} %}
	ここまでの議論では、すべての$\lambda\in\myop{eigen}_+H$で$V_n^\lambda$と
	$V_{n+1}^\lambda$が$1:1$かつ$\myop{onto}$の関係にあることが示されていない。
	\begin{equation*}\begin{split}
		Qが1:1\text{でない} & \quad Qが\myop{onto}\text{でない} \\
		\xymatrix@R=1ex{
			V_n^\lambda \ar[r]^{Q} & V_{n+1}^\lambda \\
			v_n^1 \ar[r] & v_{n+1}^1 \\
			v_n^2 \ar[ru] & v_{n+1}^2 \\
		} & \quad \xymatrix@R=1ex{
			V_n^\lambda \ar[r]^{Q} & V_{n+1}^\lambda \\
			v_n^1 \ar[rd] & v_{n+1}^1 \\
			v_n^2 \ar[rd] & v_{n+1}^2 \\
			\vdots & \vdots \\
		}
	\end{split}\end{equation*}
	次の式が成り立つことから、
	任意の$n\in\mybf{N},\;\lambda\in\myop{eigen}_+H$に対して
	$Q$と$Q^\dag$が共に$1:1$写像であることがわかる。
	\begin{equation*}\begin{split} %{
		Qv_1=Qv_2 \implies Q(v_1-v_2)=0\implies v_1=v_2
		& \quad\text{for all }v_1,v_2\in V_n^\lambda \\
		Q^\dag v_1=Q^\dag v_2 \implies Q^\dag (v_1-v_2)=0\implies v_1=v_2
		& \quad\text{for all }v_1,v_2\in V_{n+1}^\lambda \\
	\end{split}\end{equation*} %}
	また、任意の$n\in\mybf{N},\;\lambda\in\myop{eigen}_+H
	,\;v\neq0\in V_n^\lambda$に対して次の式が成り立ち、
	$Q^\dag Qv\propto v$となることがわかる。
	\begin{equation*}\begin{split} %{
		Q^\dag Q v = cv + v_\bot
		,\quad c = \frac{\zettai{Qv}^2}{\zettai{v}^2}
		,\quad v^\dag v_\bot = 0 \\
		\Downarrow \\
		Qv_\bot = (QQ^\dag - c)Qv = (H - c)Qv = (\lambda - c)Qv \\
		\Downarrow \\
		v_\bot = (\lambda - c)v \implies \zettai{v_\bot}^2 = 0
		\implies v_\bot = 0
	\end{split}\end{equation*} %}
	したがって、任意の
	$n\in\mybf{N},\;\lambda\in\myop{eigen}_+H,\;v\neq0\in V_n^\lambda$
	に対して次の式が成り立ち、$Q^\dag$が$\myop{onto}$写像であることがわかる。
	\begin{equation*}\begin{split} %{
		Q^\dag Qv = \frac{\zettai{Qv}^2}{\zettai{v}^2}v
		\Leftrightarrow 
		v = Q^\dag\left(\frac{\zettai{v}^2}{\zettai{Qv}^2}Qv\right)
		\in Q^\dag V_{n+1}^\lambda
	\end{split}\end{equation*} %}
	$Q$が$\myop{onto}$写像であることも同様に示される。したがって、
	$Q$と$Q^\dag$はともに$1:1$かつ$\myop{onto}$になることがわかる。
	$V_0,V_1,V_2$について対応関係を図にすると次のようになる。
	\begin{equation*}\begin{array}{ccccccccc} %{
		V_0 &=& V_0^0 &\oplus& V_0^{\lambda_1} &\oplus& V_0^{\lambda_1} 
			&\oplus&\cdots \\
		& & & & \text{\rotatebox[origin=c]{-90}{$\simeq$}} 
		& & \text{\rotatebox[origin=c]{-90}{$\simeq$}} \\
		V_1 &=& V_1^0 &\oplus& V_1^{\lambda_1} &\oplus& V_1^{\lambda_1} 
			&\oplus&\cdots \\
		& & & & \text{\rotatebox[origin=c]{-90}{$\simeq$}} 
		& & \text{\rotatebox[origin=c]{-90}{$\simeq$}} \\
		V_2 &=& V_2^0 &\oplus& V_2^{\lambda_1} &\oplus& V_2^{\lambda_1} 
			&\oplus&\cdots \\
	\end{array}\end{equation*} %}

	$V$が有限次元ならば、ある有限の$N\in\mybf{N}$があって、
	すべての$\lambda\in\myop{eigen}_+H$で$QV_N^\lambda=0$となる。
	したがって、
	任意の$\lambda\in\myop{eigen}_+H$で
	$\myop{dim}V_0^\lambda=\myop{dim}V_1^\lambda=\myop{dim}V_2^\lambda
	=\cdots=\myop{dim}V_N^\lambda=0$となり、$Q=0$となる。
	したがって、ここに書いている超対称モデルは、$V$が無限次元の時にのみ
	意味を持つ。
%s1:超対称性}
